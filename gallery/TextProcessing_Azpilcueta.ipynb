{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Text-Processing\" data-toc-modified-id=\"Text-Processing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Text Processing</a></div><div class=\"lev2 toc-item\"><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Introduction</a></div><div class=\"lev1 toc-item\"><a href=\"#Preparations\" data-toc-modified-id=\"Preparations-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Preparations</a></div><div class=\"lev1 toc-item\"><a href=\"#TF/IDF-\" data-toc-modified-id=\"TF/IDF--3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>TF/IDF </a></div><div class=\"lev1 toc-item\"><a href=\"#Translations?\" data-toc-modified-id=\"Translations?-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Translations?</a></div><div class=\"lev1 toc-item\"><a href=\"#Similarity-\" data-toc-modified-id=\"Similarity--5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Similarity </a></div><div class=\"lev1 toc-item\"><a href=\"#Word-Clouds-\" data-toc-modified-id=\"Word-Clouds--6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Word Clouds </a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is the continuation of preceding work. Previously, I have worked my way through a couple of text-analysing approaches - such as tf/idf frequencies, n-grams and the like - in the context of a project concerned with Juan de Solórzano Pereira's *Politica Indiana*. This can be seen [here](TextProcessing_Solorzano.ipynb).\n",
    "\n",
    "In the former context, I got somewhat stuck when I was trying to automatically align corresponding passages of two editions of the same work ... where the one edition would be a **translation** of the other and thus we would have two different languages. In vector terminology, two languages means two almost orthogonal vectors and it makes little sense to search for similarities there.\n",
    "\n",
    "The present file takes this up, tries to refine an approach taken there and to find alternative ways of analysing a text across several languages. This time, the work concerned is Martín de Azpilcueta's *Manual de confesores*, a work of the 16th century that has seen very many editions and translations, quite a few of them even by the work's original author and it is the subject of the research project [\"Martín de Azpilcueta’s Manual for Confessors and the Phenomenon of Epitomisation\"](http://www.rg.mpg.de/research/martin-de-azpilcuetas-manual-for-confessors) by Manuela Bragagnolo. \n",
    "\n",
    "(There are a few DH-ey things about the project that are not directly of concern here, like a synoptic display of several editions or the presentation of the divergence of many actual translations of a given term. Such aspects are being treated with other software, like [HyperMachiavel](http://hyperprince.ens-lyon.fr/hypermachiavel) or [Lera](http://lera.uzi.uni-halle.de/).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous case, the programming language used in the following examples is \"python\" and the tool used to get prose discussion and code samples together is called [\"jupyter\"](http://jupyter.org/). (A common way of installing both the language and the jupyter software, especially in windows, is by installing a python \"distribution\" like [Anaconda](https://www.anaconda.com/what-is-anaconda/).) In jupyter, you have a \"notebook\" that you can populate with text (if you want to use it, jupyter understands [markdown](http://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html) code formatting) or code, and a program that pipes a nice rendering of the notebook to a web browser as you are reading right now. In many places in such a notebook, the output that the code samples produce is printed right below the code itself. Sometimes this can be quite a lot of output and depending on your viewing environment you might have to scroll quite some way to get to the continuation of the discussion.\n",
    "\n",
    "You can save your notebook online (the current one is [here at github](https://github.com/awagner-mainz/notebooks/blob/master/gallery/TextProcessing_Azpilcueta.ipynb)) and there is an online service, nbviewer, able to render any notebook that it can access online. So chances are you are reading this present notebook at the web address [https://nbviewer.jupyter.org/github/awagner-mainz/notebooks/blob/master/gallery/TextProcessing_Azpilcueta.ipynb](https://nbviewer.jupyter.org/github/awagner-mainz/notebooks/blob/master/gallery/TextProcessing_Azpilcueta.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A final word about the elements of this notebook:\n",
    "\n",
    "<div class=\"alert alertbox alert-success\">At some points I am mentioning things I consider to be important decisions or take-away messages for scholarly readers. E.g. whether or not to insert certain artefacts into the very transcription of your text, what the methodological ramifications of a certain approach or parameter are, what the implications of an example solution are, or what a possible interpretation of a certain result might be. I am highlighting these things in a block like this one here or at least in <font color=\"green\">**green bold font**</font>.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alertbox alert-danger\">**NOTE:** As I am continually improving the notebook on the side of the source text, wordlists and other parameters, it is sometimes hard to keep the prose description in sync. So while the actual descriptions still apply, the numbers that are mentioned in the prose (as where we have e.g. a \"table with 20 rows and 1.672 columns\") might no longer reflect the latest state of the sources, auxiliary files and parameters and you should take these with a grain of salt. Best double check them by reading the actual code ;-)\n",
    "\n",
    "I apologize for the inconsistency.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike in the previous case, where we had word files that we could export as plaintext, in this case Manuela has prepared a sample chapter with four editions transcribed *in parallel* in an office spreadsheet. So we first of all make sure that we have good **UTF-8** comma-separated-value files, e.g. by uploading a **csv** export of our office program of choice to [a CSV Linting service](https://csvlint.io/). (As a side remark, in my case, exporting with LibreOffice provided me with options to select UTF-8 encoding and choose the field delimiter and resulted in a valid csv file. MS Excel did neither of those.) Below, we expect the file at the following position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T21:19:17.232185Z",
     "start_time": "2018-06-12T21:19:17.218934Z"
    }
   },
   "outputs": [],
   "source": [
    "sourcePath = 'Azpilcueta/cap6_align_-_2018-01.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can go ahead and open the file in python's csv reader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T21:19:17.414057Z",
     "start_time": "2018-06-12T21:19:17.398148Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "sourceFile = open(sourcePath, newline='', encoding='utf-8')\n",
    "sourceTable = csv.reader(sourceFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T15:33:14.158534Z",
     "start_time": "2018-02-05T15:33:14.154549Z"
    }
   },
   "source": [
    "And next, we read each line into new elements of four respective lists (since we're dealing with one sample chapter, we try to handle it all in memory first and see if we run into problems):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(Note here and in the following that in most cases, when the program is counting, it does so beginning with zero. Which means that if we end up with 20 segments, they are going to be called segment 0, segment 1, ..., segment 19. There is not going to be a segment bearing the number twenty, although we do have twenty segments. The first one has the number zero and the twentieth one has the number nineteen. Even for more experienced coders, this sometimes leads to mistakes, called \"off-by-one errors\".)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T21:19:17.788550Z",
     "start_time": "2018-06-12T21:19:17.753479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 rows read.\n",
      "\n",
      "1556 SPA\n",
      "¶ Capitulo.6. De las circunstancias del pecado.\n",
      "Sumario.\n",
      "1Circunstancia que es? nu. I. y que ay siete especies della.nu.2. Y que se ha de confessar de necessidad, la que muda la especie. nu. 3. Pero no la de aver pecado en confinança de se confessar.n.4./Circunstancia de homicidio, y de fornicacion en lugar sagrado se ha de confessar, y la vedada por otra ley diversa &c. nu. 5/Circunstancia de mentira iocosa, y la que alivia el pecado quando se ha de confessar.nu.6.7.  & 8. Y quando la del dia de fiesta, de ayuno, o de oracion, o del lugar sagrado. nu. 9 & 10. Y la de la proprioa persona, y de la religion. nu. 11. Y ha de pecar contra consciencia. nume.12/[p. 32,corretto 31; 24 pdf] Circunstancia como no es el numero de los pecados nu. 14. Pecaodo multipliarse tantas vezes, quantas se itera, como se ha de entender, y si crece el numero de los pecados por se interpolar la voluntad. nu. 16. Y por mudar el proposito, para no acabar el pecado con otras muchas consideraciones quotidianas. num.17&18./Confessar puede el penitente mil pecados en una sola palabra n.18./Circunstancia del pecado quando se ha de confessar de necessidad. num 19. Y la oluidada en la confession como se confessara sin tornar a confessar el pecado. nu 20\n",
      "2 [1] Para fundamento desto dezimos, quanto a lo primero, que la circunstancia del pecado, segun la mente del derechoa (ca. Consideret. de poeni. d. 5 l. Aut facta ff. de poen.c. Sicut dignum de homic) y de sus interpretes b (b : I. Sec. qo. 7 & in 4 dist 16 ubi etiam omnes alii & Anton. 3. part. tit. 17 ca. 17§ 4 & Gerson. 2. part. fol 170 quos retulimus in princ. d. c. Consideret & Pau. & aliorum in d. c. Sicut & alibi) es un accidente de aquello, che es pecado. Diximos (accidente) porque ninguna circunstancia de la obra, es la substancia della. Diximos de aquello (que es peccado) y no del peccado, porque muchas vezes la obra en si no es pecado, y se haze tal por la circunstancia, y como entonces ella es lo, en que consiste el peccado, no es tan accidente de pecado, quanto de aquello che es pecado, segun lo declaramos en otra partec (c : In d. c. Consideret. nu.3), siguiendo a Alexandro Halensed (d : In 4 par q. 77 ar. 2 col2).\n",
      "3 [2] ¶ Lo II † que la circunstancia se parte en siete species, que se contienen en un versilloe (e : f. Quis, quid, ubi, quibus auxiliis, cur, quomodo, quando), referido por S. Thomasf (f : In dict. q. 7. articu. 3). Quien, que, donde, con que, porque, como, y quando. Al qual versillo tenemos por mejor que al de Paludanog (g : In 4. dist. 16. quaest. 3. articu. I.), como lo diximos allih (h : f. in princ. dict. capitu. Consideret. numero. 4). Porque enel se añade, quoties, quantas vezes que denota numero, el qual no es circunstanci, sino multiplicacion del pecado, como allii (i : In dict. cap. Consideret. numero quarto) lo diximos.\n"
     ]
    }
   ],
   "source": [
    "    # Initialize a list of lists, or two-dimensional list ...\n",
    "    Editions = [[]]\n",
    "\n",
    "    # ...with four sub-lists 0 to 3\n",
    "    for i in range(3):\n",
    "        a = []\n",
    "        Editions.append(a)\n",
    "\n",
    "    # Now populate it from our sourceTable\n",
    "    sourceFile.seek(0)             # in repeated runs, restart from the beginning of the file\n",
    "    for row in sourceTable:\n",
    "        for i, field in enumerate(row):\n",
    "            Editions[i].append(field)\n",
    "\n",
    "    print(str(len(Editions[0])) + \" rows read.\\n\")\n",
    "\n",
    "    # As an example, see the first seven sections of the third edition (1556 SPA):\n",
    "    for field in range(6):\n",
    "        print(Editions[2][field])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, let's define two more list variables to hold information about the different editions - language and year of print:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T21:19:17.954832Z",
     "start_time": "2018-06-12T21:19:17.943865Z"
    }
   },
   "outputs": [],
   "source": [
    "numOfEds = 4\n",
    "language = [\"PT\", \"PT\", \"ES\", \"LA\"] # I am using language codes that later on can be used in babelnet\n",
    "year = [1549, 1552, 1556, 1573]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF/IDF <a name=\"tfidf\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous (i.e. Solórzano) analyses, things like tokenization, lemmatization and stop-word lists filtering are explained step by step. Here, we rely on what we have found there and feed it all into functions that are ready-made and available in suitable libraries..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we build our lemmatization resource and \"function\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T21:19:24.874516Z",
     "start_time": "2018-06-12T21:19:18.493440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614729 PT wordforms known to the system.\n",
      "614729 PT wordforms known to the system.\n",
      "614701 ES wordforms known to the system.\n",
      "1709 LA wordforms known to the system.\n"
     ]
    }
   ],
   "source": [
    "lemma = [{} for i in range(numOfEds)]\n",
    "# lemma    = {}    # we build a so-called dictionary for the lookups\n",
    "\n",
    "for i in range(numOfEds):\n",
    "    \n",
    "    wordfile_path = 'Azpilcueta/wordforms-' + language[i].lower() + '.txt'\n",
    "\n",
    "    # open the wordfile (defined above) for reading\n",
    "    wordfile = open(wordfile_path, encoding='utf-8')\n",
    "\n",
    "    tempdict = []\n",
    "    for line in wordfile.readlines():\n",
    "        tempdict.append(tuple(line.split('>'))) # we split each line by \">\" and append\n",
    "                                                # a tuple to a temporary list.\n",
    "\n",
    "    lemma[i] = {k.strip(): v.strip() for k, v in tempdict} # for every tuple in the temp. list,\n",
    "                                                    # we strip whitespace and make a key-value\n",
    "                                                    # pair, appending it to our \"lemma\"\n",
    "                                                    # dictionary\n",
    "    wordfile.close\n",
    "\n",
    "    print(str(len(lemma[i])) + ' ' + language[i] + ' wordforms known to the system.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, a quick test: Let's see with which \"lemma\"/basic word the particular wordform \"diremos\" is associated, or, in other words, what *value* our lemma variable returns when we query for the *key* \"diremos\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T21:19:24.902152Z",
     "start_time": "2018-06-12T21:19:24.878936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'decir'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma[language.index(\"ES\")]['diremos']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we are going to need the stopwords lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T21:19:24.924436Z",
     "start_time": "2018-06-12T21:19:24.905911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746 PT stopwords known to the system, e.g.: ['ciertos', 'cinco', 'claro', 'comentó', 'como', 'cómo', 'con', 'conmigo', 'conocer', 'conseguimos', 'conseguir', 'considera', 'consideró', 'consigo', 'consigue', 'consiguen', 'consigues', 'contigo', 'contra']\n",
      "\n",
      "746 PT stopwords known to the system, e.g.: ['ciertos', 'cinco', 'claro', 'comentó', 'como', 'cómo', 'con', 'conmigo', 'conocer', 'conseguimos', 'conseguir', 'considera', 'consideró', 'consigo', 'consigue', 'consiguen', 'consigues', 'contigo', 'contra']\n",
      "\n",
      "756 ES stopwords known to the system, e.g.: ['cierta', 'ciertas', 'cierto', 'ciertos', 'cinco', 'claro', 'comentó', 'como', 'cómo', 'con', 'conmigo', 'conocer', 'conseguimos', 'conseguir', 'considera', 'consideró', 'consigo', 'consigue', 'consiguen']\n",
      "\n",
      "395 LA stopwords known to the system, e.g.: ['ac', 'ad', 'adhic', 'adhuc', 'ae', 'ait', 'ali', 'alii', 'aliis', 'alio', 'aliqua', 'aliqui', 'aliquid', 'aliquis', 'aliquo', 'am', 'an', 'ante', 'apud']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(numOfEds):\n",
    "    \n",
    "    stopwords_path = 'Azpilcueta/stopwords-' + language[i].lower() + '.txt'\n",
    "    stopwords[i] = open(stopwords_path, encoding='utf-8').read().splitlines()\n",
    "\n",
    "    print(str(len(stopwords[i])) + ' ' + language[i]\n",
    "          + ' stopwords known to the system, e.g.: ' + str(stopwords[i][100:119]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(In contrast to simpler numbers that have been filtered out by the stopwords filter, I have left numbers representing years like \"1610\" in place.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we should find some very characteristic words for each segment for each edition. (Let's say we are looking for the \"Top 20\".) We should build a vocabulary for each edition individually and only afterwards work towards a common vocabulary of several \"Top n\" sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T21:19:26.103795Z",
     "start_time": "2018-06-12T21:19:24.932520Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "numTopTerms = 20\n",
    "\n",
    "# So first we build a tokenising and lemmatising function (per language) to work as\n",
    "# an input filter to the CountVectorizer function\n",
    "def ourLaLemmatiser(str_input):\n",
    "    wordforms = re.split('\\W+', str_input)\n",
    "    return [lemma[language.index(\"LA\")][wordform].lower().strip() if wordform in lemma[language.index(\"LA\")] else wordform.lower().strip() for wordform in wordforms ]\n",
    "def ourEsLemmatiser(str_input):\n",
    "    wordforms = re.split('\\W+', str_input)\n",
    "    return [lemma[language.index(\"ES\")][wordform].lower().strip() if wordform in lemma[language.index(\"ES\")] else wordform.lower().strip() for wordform in wordforms ]\n",
    "def ourPtLemmatiser(str_input):\n",
    "    wordforms = re.split('\\W+', str_input)\n",
    "    return [lemma[language.index(\"PT\")][wordform].lower().strip() if wordform in lemma[language.index(\"PT\")] else wordform.lower().strip() for wordform in wordforms ]\n",
    "\n",
    "def ourLemmatiser(lang):\n",
    "    if (lang == \"LA\"):\n",
    "        return ourLaLemmatiser\n",
    "    if (lang == \"ES\"):\n",
    "        return ourEsLemmatiser\n",
    "    if (lang == \"PT\"):\n",
    "        return ourPtLemmatiser\n",
    "\n",
    "def ourStopwords(lang):\n",
    "    if (lang == \"LA\"):\n",
    "        return stopwords[language.index(\"LA\")]\n",
    "    if (lang == \"ES\"):\n",
    "        return stopwords[language.index(\"ES\")]\n",
    "    if (lang == \"PT\"):\n",
    "        return stopwords[language.index(\"PT\")]\n",
    "\n",
    "topTerms = []\n",
    "for i in range(numOfEds):\n",
    "\n",
    "    topTermsEd = []\n",
    "    # Initialize the library's function, specifying our\n",
    "    # tokenizing function from above and our stopwords list.\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words=ourStopwords(language[i]), use_idf=True, tokenizer=ourLemmatiser(language[i]), norm='l2')\n",
    "\n",
    "    # Finally, we feed our corpus to the function to build a new \"tfidf_matrix\" object\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(Editions[i])\n",
    "\n",
    "    # convert your matrix to an array to loop over it\n",
    "    mx_array = tfidf_matrix.toarray()\n",
    "\n",
    "    # get your feature names\n",
    "    fn = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "    # now loop through all segments and get the respective top n words.\n",
    "    pos = 0\n",
    "    for j in mx_array:\n",
    "        # We have empty segments, i.e. none of the words in our vocabulary has any tf/idf score > 0\n",
    "        if (j.max() == 0):\n",
    "            topTermsEd.append([(\"\", 0)])\n",
    "        # otherwise append (present) lemmatised words until numTopTerms or the number of words (-stopwords) is reached\n",
    "        else:\n",
    "            topTermsEd.append(\n",
    "                [(fn[x], j[x]) for x in ((j*-1).argsort()) if j[x] > 0] \\\n",
    "                [:min(numTopTerms, len(\n",
    "                    [word for word in re.split('\\W+', Editions[i][pos]) if ourLemmatiser(language[i])(word) not in stopwords]\n",
    "                ))])\n",
    "        pos += 1\n",
    "    topTerms.append(topTermsEd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T12:30:15.482766Z",
     "start_time": "2017-08-30T14:30:15.474338+02:00"
    }
   },
   "source": [
    "# Translations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe there is an approach to inter-lingual comparison after all. After a first unsuccessful try with [conceptnet.io](http://conceptnet.io), I next want to try [Babelnet](http://babelnet.org) in order to lookup synonyms, related terms and translations. I still have to study the [API](http://babelnet.org/guide)...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let's take this single segment 19:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T21:19:26.110945Z",
     "start_time": "2018-06-12T21:19:26.107019Z"
    }
   },
   "outputs": [],
   "source": [
    "segment_no = 19 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then first let's see how this segment compares in the different editions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T21:24:08.291186Z",
     "start_time": "2018-06-12T21:24:08.259440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing words from segments 19 ...\n",
      " \n",
      "Here is the segment in the four editions:\n",
      " \n",
      "Ed. 0:\n",
      "------\n",
      "¶A circunstancia do dia deputado a jejuum, ou oraçam : nam he de necessidade confessata : salvo quando fizesse peccado com proposito de ho quebrantar como acima do dia da festa. Segundo Navarro, ubi supra.\n",
      " \n",
      "Ed. 1:\n",
      "------\n",
      " ¶ A IX que a circunstancia do dia de jejuũ, ou de oração, não se ha de confessar necessariamente, se não quando se pecca com proposito de ho quebrãtar : porque nã faz algũa das ditas tres cousas, segũdo em outra parte ho provamoss (s : f. in d. c. Consideret n. 32 vers. sic. Ad primum) \n",
      " \n",
      "Ed. 2:\n",
      "------\n",
      "17 ¶  El X que la circunstancia del dia de ayuno, o de oracion, no se ha de confessar necessariamente, fino quando se peca con proposito delo quebrantar, por ello por que no haze alguna delas dichas tres cosas, segun lo provamos alibim (m : in d. c. Consideret nu. 32 ver. Ad primum) \n",
      " \n",
      "Ed. 3:\n",
      "------\n",
      "17Decimo. Quod circunstantia diei ieiunio vel orationi consecrati, licet videatur aliquantulum augere peccatum, non est de necessitate confitenda, nisi peccatum perpetretur cum proposito violandi  per illud huiusmodi diem; Quoniam non efficit mortale, quod alias non [p. 69r, 150 pdf] esset tale, nec mutat in speciem mortalis, nec facit ut novo respectu sit tale quorum aliquod requiritur ad hoc un circunstantiae fonfessio sit necessaria, ut supra dictum est nu. 3. & probabimus in princip. dicti. c. Consideret, nu. 32 verb. Ad primum.\n",
      " \n",
      " \n",
      " \n",
      "Most significant words in the segment:\n",
      " \n",
      "Ed. 0:\n",
      "------\n",
      "[('do', 0.28400232496863814), ('diputar', 0.28297270068902536), ('oraçam', 0.28297270068902536), ('fizesse', 0.28297270068902536), ('jejunum', 0.28297270068902536), ('acima', 0.28297270068902536), ('confessata', 0.28297270068902536), ('salvar', 0.25460456614577454), ('quebrantar', 0.25460456614577454), ('supra', 0.21886494334383444), ('uve', 0.21886494334383444), ('propósito', 0.21886494334383444), ('navarro', 0.17774078528625914), ('circunstancia', 0.17036929702756992), ('necessidade', 0.16370097477255297), ('ho', 0.14200116248431907), ('pecado', 0.14200116248431907), ('nam', 0.13748576174023172), ('ou', 0.13748576174023172)]\n",
      " \n",
      "Ed. 1:\n",
      "------\n",
      "[('primum', 0.26630110430549364), ('oração', 0.26630110430549364), ('sic', 0.26630110430549364), ('jejunum', 0.26630110430549364), ('vers', 0.26630110430549364), ('32', 0.26630110430549364), ('provamoss', 0.26630110430549364), ('quebrãtar', 0.2396043044461442), ('ad', 0.2206626235029858), ('peca', 0.20597031432468096), ('propósito', 0.20597031432468096), ('necessariamente', 0.20597031432468096), ('ho', 0.20000208708272071), ('nã', 0.17502414270047792), ('s', 0.1672690237842868), ('cousas', 0.1672690237842868), ('faz', 0.14832734284112842), ('consideret', 0.1381776905893417), ('f', 0.1336350336628236), ('hem', 0.1253939906966336)]\n",
      " \n",
      "Ed. 2:\n",
      "------\n",
      "[('finar', 0.3441461903033127), ('alibim', 0.3441461903033127), ('primum', 0.3441461903033127), ('oración', 0.3096453872035803), ('ayunar', 0.3096453872035803), ('quebrantar', 0.2851666778436269), ('propósito', 0.2851666778436269), ('necessariamente', 0.2506658747438945), ('peca', 0.23754927815874174), ('probar', 0.23754927815874174), ('consideret', 0.19909011250814895), ('cosa', 0.19168636228420863), ('confesar', 0.1401106000484631), ('circunstancia', 0.1363282240135731)]\n",
      " \n",
      "Ed. 3:\n",
      "------\n",
      "[('dies', 0.3028053715975367), ('tale', 0.24590902368540443), ('requiro', 0.19575006502865927), ('probabimus', 0.19575006502865927), ('augere', 0.19575006502865927), ('consecrati', 0.19575006502865927), ('ieiunio', 0.19575006502865927), ('fonfessio', 0.19575006502865927), ('perpetretur', 0.19575006502865927), ('aliquantulum', 0.19575006502865927), ('oratio', 0.19575006502865927), ('necessitas', 0.1761260370992454), ('violandi', 0.1761260370992454), ('novo', 0.1761260370992454), ('princip', 0.16220256770152996), ('proposito', 0.16220256770152996), ('video', 0.16220256770152996), ('circumstantia', 0.15140268579876834), ('necessarius', 0.15140268579876834), ('mutat', 0.15140268579876834)]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"Comparing words from segments \" + str(segment_no) + \" ...\")\n",
    "\n",
    "print(\" \")\n",
    "print(\"Here is the segment in the four editions:\")\n",
    "print(\" \")\n",
    "for i in range(numOfEds):\n",
    "    print(\"Ed. \" + str(i) + \":\")\n",
    "    print(\"------\")\n",
    "    print(Editions[i][segment_no])\n",
    "    print(\" \")\n",
    "\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "\n",
    "# Build List of most significant words for a segment\n",
    "\n",
    "print(\"Most significant words in the segment:\")\n",
    "print(\" \")\n",
    "for i in range(numOfEds):\n",
    "    print(\"Ed. \" + str(i) + \":\")\n",
    "    print(\"------\")\n",
    "    print(topTerms[i][segment_no])\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we look up the \"concepts\" associated to those words in babelnet. Then we look up the concepts associated with the words of the present segment from another edition/language, and see if the concepts are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we have to decide on some particular editions to get things started. Let's take the Spanish and Latin ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T21:25:07.983884Z",
     "start_time": "2018-06-12T21:25:07.971245Z"
    }
   },
   "outputs": [],
   "source": [
    "startEd = 2\n",
    "secondEd = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can continue..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T21:25:20.963938Z",
     "start_time": "2018-06-12T21:25:11.204219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "For each of the 'ES' words, here are possible synsets:\n",
      " \n",
      "finar: bn:00084343v\n",
      " \n",
      "oración: bn:00064039n, bn:00059529n, bn:00070528n, bn:00059274n, bn:00064040n, bn:08296656n, bn:00059276n, bn:00059244n\n",
      " \n",
      "ayunar: bn:00088050v, bn:00033737n, bn:00088049v\n",
      " \n",
      "quebrantar: bn:00083911v, bn:00093586v, bn:00083904v\n",
      " \n",
      "propósito: bn:00074900n, bn:00030721n, bn:00002178n, bn:00026651n, bn:00036822n, bn:00047046n, bn:00028724n\n",
      " \n",
      "peca: bn:00036309n\n",
      " \n",
      "probar: bn:00092112v, bn:00086567v, bn:00088852v, bn:00094413v, bn:00094833v, bn:00094834v, bn:00093251v, bn:00092109v, bn:00087867v, bn:00087731v, bn:00095207v, bn:00082844v, bn:00083245v, bn:00092110v, bn:00086679v\n",
      " \n",
      "cosa: bn:00076928n, bn:16956461n, bn:00076927n, bn:00058442n, bn:00076925n, bn:11368151n, bn:00076924n, bn:00074798n, bn:16512490n, bn:00076923n, bn:00076922n, bn:00076921n, bn:00076920n, bn:01260156n, bn:00028240n, bn:00053801n, bn:00001734n, bn:11389907n, bn:03630544n, bn:00750164n, bn:16854696n, bn:00076919n, bn:00076918n\n",
      " \n",
      "confesar: bn:00082961v, bn:00085576v, bn:00085511v, bn:00085575v\n",
      " \n",
      "circunstancia: bn:00019220n, bn:00019219n, bn:00019218n, bn:08375592n\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "For each of the 'LA' words, here are possible synsets:\n",
      " \n",
      "dies: bn:17999879n\n",
      " \n",
      "tale: bn:14730014n, bn:14687123n\n",
      " \n",
      "oratio: bn:00059529n, bn:16473014n\n",
      " \n",
      "necessitas: bn:03277980n\n",
      " \n",
      "video: bn:00079647n, bn:00079978n, bn:00079972n, bn:08263853n, bn:08263856n, bn:06336203n, bn:00076373n\n",
      " \n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "babelAPIKey = '18546fd3-8999-43db-ac31-dc113506f825'\n",
    "babelGetSynsetIdsURL = \"https://babelnet.io/v5/getSynsetIds?\" + \\\n",
    "                       \"targetLang=LA&targetLang=ES&targetLang=PT\" + \\\n",
    "                       \"&searchLang=\" + language[startEd] + \\\n",
    "                       \"&key=\" + babelAPIKey + \\\n",
    "                       \"&lemma=\"\n",
    "\n",
    "# Build lists of possible concepts\n",
    "top_possible_conceptIDs = defaultdict(list)\n",
    "for (word, val) in topTerms[startEd][segment_no]:\n",
    "    concepts_uri = babelGetSynsetIdsURL + urllib.parse.quote(word)\n",
    "    response = urllib.request.urlopen(concepts_uri)\n",
    "    conceptIDs = json.loads(response.read().decode(response.info().get_param('charset') or 'utf-8'))\n",
    "    for rel in conceptIDs:\n",
    "        top_possible_conceptIDs[word].append(rel.get(\"id\"))\n",
    "\n",
    "print(\" \")\n",
    "print(\"For each of the '\" + language[startEd] + \"' words, here are possible synsets:\")\n",
    "print(\" \")\n",
    "\n",
    "for word in top_possible_conceptIDs:\n",
    "    print(word + \":\" + \" \" + ', '.join(c for c in top_possible_conceptIDs[word]))\n",
    "    print(\" \")\n",
    "\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "\n",
    "babelGetSynsetIdsURL2 = \"https://babelnet.io/v5/getSynsetIds?\" + \\\n",
    "                        \"targetLang=LA&targetLang=ES&targetLang=PT\" + \\\n",
    "                        \"&searchLang=\" + language[secondEd] + \\\n",
    "                        \"&key=\" + babelAPIKey + \\\n",
    "                        \"&lemma=\"\n",
    "\n",
    "# Build list of 10 most significant words in the second language\n",
    "top_possible_conceptIDs_2 = defaultdict(list)\n",
    "for (word, val) in topTerms[secondEd][segment_no]:\n",
    "    concepts_uri = babelGetSynsetIdsURL + urllib.parse.quote(word)\n",
    "    response = urllib.request.urlopen(concepts_uri)\n",
    "    conceptIDs = json.loads(response.read().decode(response.info().get_param('charset') or 'utf-8'))\n",
    "    for rel in conceptIDs:\n",
    "        top_possible_conceptIDs_2[word].append(rel.get(\"id\"))\n",
    "\n",
    "print(\" \")\n",
    "print(\"For each of the '\" + language[secondEd] + \"' words, here are possible synsets:\")\n",
    "print(\" \")\n",
    "for word in top_possible_conceptIDs_2:\n",
    "    print(word + \":\" + \" \" + ', '.join(c for c in top_possible_conceptIDs_2[word]))\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T21:33:50.770845Z",
     "start_time": "2018-06-12T21:33:50.207466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlaps: {'bn:00059529n'}\n",
      "https://babelnet.io/v5/getSynset?key=18546fd3-8999-43db-ac31-dc113506f825&targetLang=LA&targetLang=ES&targetLang=PT&id=bn:00059529n\n",
      "bn:00059529n: comunión (es)\n"
     ]
    }
   ],
   "source": [
    "# calculate number of overlapping terms\n",
    "values_a = set([item for sublist in top_possible_conceptIDs.values() for item in sublist])\n",
    "values_b = set([item for sublist in top_possible_conceptIDs_2.values() for item in sublist])\n",
    "overlaps = values_a & values_b\n",
    "print(\"Overlaps: \" + str(overlaps))\n",
    "\n",
    "babelGetSynsetInfoURL = \"https://babelnet.io/v5/getSynset?key=\" + babelAPIKey + \\\n",
    "                        \"&targetLang=LA&targetLang=ES&targetLang=PT\" + \\\n",
    "                        \"&id=\"\n",
    "\n",
    "for c in overlaps:\n",
    "    info_uri = babelGetSynsetInfoURL + c\n",
    "    response = urllib.request.urlopen(info_uri)\n",
    "    words = json.loads(response.read().decode(response.info().get_param('charset') or 'utf-8'))\n",
    "    \n",
    "    senses = words['senses']\n",
    "    for result in senses[:1]:\n",
    "        lemma = result['properties'].get('fullLemma')\n",
    "        language = result['properties'].get('language')\n",
    "        print(c + \": \" + lemma + \" (\" + language.lower() + \")\")\n",
    "\n",
    "# do a nifty ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T07:42:37.598721Z",
     "start_time": "2017-07-11T09:42:37.587926+02:00"
    }
   },
   "source": [
    "# Similarity <a name=\"DocumentSimilarity\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems we could now create another matrix replacing lemmata with concepts and retaining the tf/idf values (so as to keep a weight coefficient to the concepts). Then we should be able to calculate similarity measures across the same concepts...\n",
    "\n",
    "The approach to choose would probably be the \"cosine similarity\" of concept vector spaces. Again, there is a library ready for us to use (but you can find some documentation [here](http://blog.christianperone.com/2013/09/machine-learning-cosine-similarity-for-vector-space-models-part-iii/), [here](http://scikit-learn.org/stable/modules/metrics.html#cosine-similarity) and [here](https://en.wikipedia.org/wiki/Cosine_similarity).)\n",
    "\n",
    "**However, this is where I have to take a break now. I will return to here soon...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T21:38:22.485025Z",
     "start_time": "2018-06-12T21:38:21.992985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise similarities:\n",
      "     0         1    2         3         4         5         6         7   \\\n",
      "0   0.0  0.000000  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "1   0.0  0.000000  0.0  0.027305  0.042553  0.021084  0.050231  0.000000   \n",
      "2   0.0  0.000000  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "3   0.0  0.027305  0.0  0.000000  0.090117  0.141109  0.109094  0.017595   \n",
      "4   0.0  0.042553  0.0  0.090117  0.000000  0.125574  0.125320  0.046224   \n",
      "5   0.0  0.021084  0.0  0.141109  0.125574  0.000000  0.059634  0.000000   \n",
      "6   0.0  0.050231  0.0  0.109094  0.125320  0.059634  0.000000  0.049117   \n",
      "7   0.0  0.000000  0.0  0.017595  0.046224  0.000000  0.049117  0.000000   \n",
      "8   0.0  0.000000  0.0  0.059207  0.033151  0.075654  0.015600  0.008134   \n",
      "9   0.0  0.000000  0.0  0.032621  0.043815  0.065289  0.069260  0.068591   \n",
      "10  0.0  0.000000  0.0  0.016428  0.036763  0.036655  0.058454  0.062323   \n",
      "11  0.0  0.011712  0.0  0.067984  0.072415  0.036169  0.122698  0.031095   \n",
      "12  0.0  0.000000  0.0  0.160030  0.022422  0.033328  0.083884  0.000000   \n",
      "13  0.0  0.000000  0.0  0.054214  0.029627  0.011612  0.072867  0.112857   \n",
      "14  0.0  0.000000  0.0  0.097183  0.116073  0.057610  0.096896  0.090284   \n",
      "15  0.0  0.035972  0.0  0.154916  0.098061  0.059986  0.221175  0.091474   \n",
      "16  0.0  0.000000  0.0  0.037549  0.010105  0.047335  0.009158  0.000000   \n",
      "17  0.0  0.000000  0.0  0.042433  0.034487  0.044521  0.048358  0.000000   \n",
      "18  0.0  0.000000  0.0  0.154361  0.124987  0.071617  0.084758  0.098344   \n",
      "19  0.0  0.000000  0.0  0.159121  0.096884  0.065863  0.162756  0.079144   \n",
      "20  0.0  0.015869  0.0  0.193187  0.142919  0.049285  0.162523  0.053908   \n",
      "21  0.0  0.000000  0.0  0.124126  0.097791  0.073204  0.036175  0.020042   \n",
      "22  0.0  0.000000  0.0  0.133874  0.110329  0.054183  0.135288  0.083511   \n",
      "23  0.0  0.000000  0.0  0.071636  0.067279  0.011366  0.055709  0.030788   \n",
      "24  0.0  0.030488  0.0  0.088891  0.150308  0.065725  0.057481  0.008854   \n",
      "25  0.0  0.000000  0.0  0.017323  0.071296  0.064632  0.065553  0.009677   \n",
      "26  0.0  0.000000  0.0  0.006772  0.031542  0.022593  0.035796  0.000000   \n",
      "27  0.0  0.000000  0.0  0.063837  0.062382  0.027493  0.039229  0.012902   \n",
      "28  0.0  0.010332  0.0  0.035458  0.104802  0.048633  0.075337  0.012003   \n",
      "29  0.0  0.000000  0.0  0.052837  0.112731  0.032380  0.062678  0.026208   \n",
      "30  0.0  0.000000  0.0  0.041566  0.063779  0.032575  0.058143  0.015597   \n",
      "31  0.0  0.000000  0.0  0.071103  0.067128  0.042885  0.034896  0.012810   \n",
      "32  0.0  0.018390  0.0  0.145957  0.112871  0.078804  0.140514  0.013582   \n",
      "33  0.0  0.000000  0.0  0.049708  0.061227  0.035691  0.059008  0.003967   \n",
      "34  0.0  0.040438  0.0  0.126692  0.162316  0.032188  0.133896  0.061426   \n",
      "35  0.0  0.000000  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "36  0.0  0.000000  0.0  0.000000  0.000000  0.000000  0.018074  0.000000   \n",
      "37  0.0  0.062948  0.0  0.104049  0.127452  0.051620  0.079348  0.065224   \n",
      "38  0.0  0.059120  0.0  0.136369  0.047433  0.097993  0.042143  0.000000   \n",
      "39  0.0  0.000000  0.0  0.006026  0.000000  0.055509  0.006593  0.000000   \n",
      "40  0.0  0.000000  0.0  0.064789  0.000000  0.025014  0.023118  0.000000   \n",
      "\n",
      "          8         9     ...           31        32        33        34   35  \\\n",
      "0   0.000000  0.000000    ...     0.000000  0.000000  0.000000  0.000000  0.0   \n",
      "1   0.000000  0.000000    ...     0.000000  0.018390  0.000000  0.040438  0.0   \n",
      "2   0.000000  0.000000    ...     0.000000  0.000000  0.000000  0.000000  0.0   \n",
      "3   0.059207  0.032621    ...     0.071103  0.145957  0.049708  0.126692  0.0   \n",
      "4   0.033151  0.043815    ...     0.067128  0.112871  0.061227  0.162316  0.0   \n",
      "5   0.075654  0.065289    ...     0.042885  0.078804  0.035691  0.032188  0.0   \n",
      "6   0.015600  0.069260    ...     0.034896  0.140514  0.059008  0.133896  0.0   \n",
      "7   0.008134  0.068591    ...     0.012810  0.013582  0.003967  0.061426  0.0   \n",
      "8   0.000000  0.007214    ...     0.037390  0.042175  0.035849  0.071476  0.0   \n",
      "9   0.007214  0.000000    ...     0.022613  0.039616  0.079450  0.022229  0.0   \n",
      "10  0.000000  0.250881    ...     0.017674  0.023031  0.024953  0.026100  0.0   \n",
      "11  0.043268  0.095401    ...     0.003044  0.073104  0.076155  0.048457  0.0   \n",
      "12  0.022137  0.035617    ...     0.000000  0.007267  0.000000  0.026242  0.0   \n",
      "13  0.036345  0.053630    ...     0.007142  0.044193  0.055963  0.070620  0.0   \n",
      "14  0.071568  0.039199    ...     0.049616  0.121000  0.111957  0.130463  0.0   \n",
      "15  0.048570  0.081466    ...     0.068120  0.144595  0.071582  0.149864  0.0   \n",
      "16  0.038510  0.030263    ...     0.000000  0.019731  0.049492  0.009800  0.0   \n",
      "17  0.039646  0.073669    ...     0.015326  0.089802  0.013724  0.009217  0.0   \n",
      "18  0.039220  0.049553    ...     0.032830  0.198516  0.016527  0.046989  0.0   \n",
      "19  0.061315  0.075151    ...     0.081260  0.129915  0.020737  0.063573  0.0   \n",
      "20  0.021019  0.027544    ...     0.023379  0.122455  0.017017  0.088156  0.0   \n",
      "21  0.024593  0.052276    ...     0.060492  0.063907  0.082189  0.077856  0.0   \n",
      "22  0.025560  0.110415    ...     0.087470  0.117060  0.067016  0.063829  0.0   \n",
      "23  0.018726  0.037877    ...     0.029601  0.111474  0.020340  0.086060  0.0   \n",
      "24  0.036597  0.007852    ...     0.049809  0.062476  0.047900  0.067180  0.0   \n",
      "25  0.047938  0.054596    ...     0.064741  0.050052  0.050255  0.050340  0.0   \n",
      "26  0.017448  0.020330    ...     0.035529  0.040105  0.083563  0.019233  0.0   \n",
      "27  0.030328  0.020985    ...     0.044662  0.112004  0.027466  0.112160  0.0   \n",
      "28  0.024383  0.031410    ...     0.053869  0.054333  0.038207  0.089689  0.0   \n",
      "29  0.052602  0.037703    ...     0.065073  0.082346  0.095508  0.119907  0.0   \n",
      "30  0.026547  0.021251    ...     0.045095  0.046977  0.085647  0.064135  0.0   \n",
      "31  0.037390  0.022613    ...     0.000000  0.032989  0.029188  0.067437  0.0   \n",
      "32  0.042175  0.039616    ...     0.032989  0.000000  0.042016  0.113518  0.0   \n",
      "33  0.035849  0.079450    ...     0.029188  0.042016  0.000000  0.090345  0.0   \n",
      "34  0.071476  0.022229    ...     0.067437  0.113518  0.090345  0.000000  0.0   \n",
      "35  0.000000  0.000000    ...     0.000000  0.000000  0.000000  0.000000  0.0   \n",
      "36  0.000000  0.000000    ...     0.039250  0.095895  0.000000  0.078445  0.0   \n",
      "37  0.000000  0.011697    ...     0.000000  0.053728  0.078727  0.070316  0.0   \n",
      "38  0.000000  0.010985    ...     0.000000  0.036839  0.016184  0.051064  0.0   \n",
      "39  0.000000  0.008186    ...     0.000000  0.012176  0.012060  0.004463  0.0   \n",
      "40  0.000000  0.000000    ...     0.000000  0.043635  0.000000  0.000000  0.0   \n",
      "\n",
      "          36        37        38        39        40  \n",
      "0   0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "1   0.000000  0.062948  0.059120  0.000000  0.000000  \n",
      "2   0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "3   0.000000  0.104049  0.136369  0.006026  0.064789  \n",
      "4   0.000000  0.127452  0.047433  0.000000  0.000000  \n",
      "5   0.000000  0.051620  0.097993  0.055509  0.025014  \n",
      "6   0.018074  0.079348  0.042143  0.006593  0.023118  \n",
      "7   0.000000  0.065224  0.000000  0.000000  0.000000  \n",
      "8   0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "9   0.000000  0.011697  0.010985  0.008186  0.000000  \n",
      "10  0.000000  0.039242  0.000000  0.000000  0.000000  \n",
      "11  0.028347  0.036062  0.033869  0.015510  0.000000  \n",
      "12  0.000000  0.000000  0.000000  0.056147  0.000000  \n",
      "13  0.000000  0.057521  0.016281  0.012132  0.000000  \n",
      "14  0.000000  0.049634  0.006401  0.004770  0.025640  \n",
      "15  0.026378  0.050729  0.028986  0.022989  0.018445  \n",
      "16  0.000000  0.016176  0.015193  0.011321  0.000000  \n",
      "17  0.000000  0.015215  0.014290  0.010648  0.000000  \n",
      "18  0.000000  0.019960  0.000000  0.000000  0.030026  \n",
      "19  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "20  0.000000  0.053875  0.027090  0.007005  0.018828  \n",
      "21  0.000000  0.120782  0.033570  0.025016  0.000000  \n",
      "22  0.135610  0.021668  0.006133  0.004570  0.024565  \n",
      "23  0.123917  0.058031  0.000000  0.000000  0.027535  \n",
      "24  0.000000  0.036184  0.066133  0.000000  0.000000  \n",
      "25  0.000000  0.010508  0.162382  0.094819  0.000000  \n",
      "26  0.000000  0.009892  0.009290  0.006923  0.000000  \n",
      "27  0.039532  0.009340  0.040003  0.035757  0.017568  \n",
      "28  0.000000  0.038331  0.057790  0.018244  0.000000  \n",
      "29  0.000000  0.032718  0.030729  0.039958  0.000000  \n",
      "30  0.000000  0.010524  0.029474  0.044240  0.000000  \n",
      "31  0.039250  0.000000  0.000000  0.000000  0.000000  \n",
      "32  0.095895  0.053728  0.036839  0.012176  0.043635  \n",
      "33  0.000000  0.078727  0.016184  0.012060  0.000000  \n",
      "34  0.078445  0.070316  0.051064  0.004463  0.000000  \n",
      "35  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "36  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "37  0.000000  0.000000  0.333028  0.027787  0.000000  \n",
      "38  0.000000  0.333028  0.000000  0.129552  0.000000  \n",
      "39  0.000000  0.027787  0.129552  0.000000  0.000000  \n",
      "40  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "\n",
      "[41 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarities = pd.DataFrame(cosine_similarity(tfidf_matrix))\n",
    "similarities[round(similarities, 0) == 1] = 0 # Suppress a document's similarity to itself\n",
    "print(\"Pairwise similarities:\")\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T21:38:27.202958Z",
     "start_time": "2018-06-12T21:38:27.154566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two most similar segments in the corpus are\n",
      "segments 37 and 38 .\n",
      "They have a similarity score of\n",
      "0.3330275428005039\n"
     ]
    }
   ],
   "source": [
    "print(\"The two most similar segments in the corpus are\")\n",
    "print(\"segments\", \\\n",
    "      similarities[similarities == similarities.values.max()].idxmax(axis=0).idxmax(axis=1), \\\n",
    "      \"and\", \\\n",
    "      similarities[similarities == similarities.values.max()].idxmax(axis=0)[ similarities[similarities == similarities.values.max()].idxmax(axis=0).idxmax(axis=1) ].astype(int), \\\n",
    "      \".\")\n",
    "print(\"They have a similarity score of\")\n",
    "print(similarities.values.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alertbox alert-success\">Of course, in every set of documents, we will always find two that are similar in the sense of them being more similar to each other than to the other ones. Whether or not this actually *means* anything in terms of content is still up to scholarly interpretation. But at least it means that a scholar can look at the two documents and when she determines that they are not so similar after all, then perhaps there is something interesting to say about similar vocabulary used for different puproses. Or the other way round: When the scholar knows that two passages are similar, but they have a low \"similarity score\", shouldn't that say something about the texts's rhetorics?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Clouds <a name=\"WordClouds\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a library that takes word frequencies like above, calculates corresponding relative sizes of words and creates nice wordcloud images for our sections (again, taking the fourth segment as an example) like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T14:04:24.972202Z",
     "start_time": "2018-03-06T14:04:24.938112Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-91283a5980e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# We make tuples of (lemma, tf/idf score) for one of our segments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# But we have to convert our tf/idf weights to pseudo-frequencies (i.e. integer numbers)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We make tuples of (lemma, tf/idf score) for one of our segments\n",
    "# But we have to convert our tf/idf weights to pseudo-frequencies (i.e. integer numbers)\n",
    "frq = [ int(round(x * 100000, 0)) for x in Editions[1][3]]\n",
    "freq = dict(zip(fn, frq))\n",
    "\n",
    "wc = WordCloud(background_color=None, mode=\"RGBA\", max_font_size=40, relative_scaling=1).fit_words(freq)\n",
    "\n",
    "# Now show/plot the wordcloud\n",
    "plt.figure()\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have a nicer overview over the many segments than is possible in this notebook, let's create a new html file listing some of the characteristics that we have found so far..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T14:03:36.623068Z",
     "start_time": "2018-03-06T14:02:47.584Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputDir = \"Azpilcueta\"\n",
    "htmlfile = open(outputDir + '/Overview.html', encoding='utf-8', mode='w')\n",
    "\n",
    "# Write the html header and the opening of a layout table\n",
    "htmlfile.write(\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "    <head>\n",
    "        <title>Section Characteristics</title>\n",
    "        <meta charset=\"utf-8\"/>\n",
    "    </head>\n",
    "    <body>\n",
    "        <table>\n",
    "\"\"\")\n",
    "\n",
    "a = [[]]\n",
    "a.clear()\n",
    "dicts = []\n",
    "w = []\n",
    "\n",
    "# For each segment, create a wordcloud and write it along with label and\n",
    "# other information into a new row of the html table\n",
    "for i in range(len(mx_array)):\n",
    "    # this is like above in the single-segment example...\n",
    "    a.append([ int(round(x * 100000, 0)) for x in mx_array[i]])\n",
    "    dicts.append(dict(zip(fn, a[i])))\n",
    "    w.append(WordCloud(background_color=None, mode=\"RGBA\", \\\n",
    "                       max_font_size=40, min_font_size=10, \\\n",
    "                       max_words=60, relative_scaling=0.8).fit_words(dicts[i]))\n",
    "    # We write the wordcloud image to a file\n",
    "    w[i].to_file(outputDir + '/wc_' + str(i) + '.png')\n",
    "    # Finally we write the column row\n",
    "    htmlfile.write(\"\"\"\n",
    "            <tr>\n",
    "                <td>\n",
    "                    <head>Section {a}: <b>{b}</b></head><br/>\n",
    "                    <img src=\"./wc_{a}.png\"/><br/>\n",
    "                    <small><i>length: {c} words</i></small>\n",
    "                </td>\n",
    "            </tr>\n",
    "            <tr><td>&nbsp;</td></tr>\n",
    "\"\"\".format(a = str(i), b = label[i], c = len(tokenised[i])))\n",
    "\n",
    "# And then we write the end of the html file.\n",
    "htmlfile.write(\"\"\"\n",
    "        </table>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\")\n",
    "htmlfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should have created a nice html file which we can open [here](./Solorzano/Overview.html)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "245px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": "2",
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
