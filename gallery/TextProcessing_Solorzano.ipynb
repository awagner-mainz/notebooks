{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Text-Processing\" data-toc-modified-id=\"Text-Processing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Text Processing</a></div><div class=\"lev2 toc-item\"><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Introduction</a></div><div class=\"lev1 toc-item\"><a href=\"#Preparations\" data-toc-modified-id=\"Preparations-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Preparations</a></div><div class=\"lev2 toc-item\"><a href=\"#Get-fulltext-\" data-toc-modified-id=\"Get-fulltext--21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Get fulltext </a></div><div class=\"lev2 toc-item\"><a href=\"#Segment-source-text\" data-toc-modified-id=\"Segment-source-text-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Segment source text</a></div><div class=\"lev2 toc-item\"><a href=\"#Read-segments-into-a-variable-\" data-toc-modified-id=\"Read-segments-into-a-variable--23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Read segments into a variable </a></div><div class=\"lev2 toc-item\"><a href=\"#Tokenising-\" data-toc-modified-id=\"Tokenising--24\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Tokenising </a></div><div class=\"lev3 toc-item\"><a href=\"#Nicer-layout:-tables-instead-of-lists-of-tuples\" data-toc-modified-id=\"Nicer-layout:-tables-instead-of-lists-of-tuples-241\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Nicer layout: tables instead of lists of tuples</a></div><div class=\"lev2 toc-item\"><a href=\"#Stemming-/-Lemmatising-\" data-toc-modified-id=\"Stemming-/-Lemmatising--25\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Stemming / Lemmatising </a></div><div class=\"lev2 toc-item\"><a href=\"#Eliminate-Stopwords-\" data-toc-modified-id=\"Eliminate-Stopwords--26\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Eliminate Stopwords </a></div><div class=\"lev1 toc-item\"><a href=\"#Characterise-passages:-TF/IDF\" data-toc-modified-id=\"Characterise-passages:-TF/IDF-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Characterise passages: TF/IDF</a></div><div class=\"lev2 toc-item\"><a href=\"#Build-vocabulary-\" data-toc-modified-id=\"Build-vocabulary--31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Build vocabulary </a></div><div class=\"lev2 toc-item\"><a href=\"#Calculate-Terms'-Text-Frequencies-(TF)-\" data-toc-modified-id=\"Calculate-Terms'-Text-Frequencies-(TF)--32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Calculate Terms' Text Frequencies (TF) </a></div><div class=\"lev2 toc-item\"><a href=\"#Normalise-TF-\" data-toc-modified-id=\"Normalise-TF--33\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Normalise TF </a></div><div class=\"lev2 toc-item\"><a href=\"#Inverse-Document-Frequencies-(IDF)-and-TF-IDF-\" data-toc-modified-id=\"Inverse-Document-Frequencies-(IDF)-and-TF-IDF--34\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Inverse Document Frequencies (IDF) and TF-IDF </a></div><div class=\"lev1 toc-item\"><a href=\"#Vector-Space-Model-of-the-text-\" data-toc-modified-id=\"Vector-Space-Model-of-the-text--4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Vector Space Model of the text </a></div><div class=\"lev2 toc-item\"><a href=\"#Another-method-to-generate-the-dimensions:-n-grams-\" data-toc-modified-id=\"Another-method-to-generate-the-dimensions:-n-grams--41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Another method to generate the dimensions: n-grams </a></div><div class=\"lev2 toc-item\"><a href=\"#Extending-the-dimensions-\" data-toc-modified-id=\"Extending-the-dimensions--42\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Extending the dimensions </a></div><div class=\"lev2 toc-item\"><a href=\"#Word-Clouds-\" data-toc-modified-id=\"Word-Clouds--43\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Word Clouds </a></div><div class=\"lev2 toc-item\"><a href=\"#Similarity-\" data-toc-modified-id=\"Similarity--44\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Similarity </a></div><div class=\"lev2 toc-item\"><a href=\"#Clustering-\" data-toc-modified-id=\"Clustering--45\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Clustering </a></div><div class=\"lev1 toc-item\"><a href=\"#Working-with-several-languages\" data-toc-modified-id=\"Working-with-several-languages-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Working with several languages</a></div><div class=\"lev2 toc-item\"><a href=\"#Translations?\" data-toc-modified-id=\"Translations?-51\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Translations?</a></div><div class=\"lev1 toc-item\"><a href=\"#Graph-based-NLP\" data-toc-modified-id=\"Graph-based-NLP-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Graph-based NLP</a></div><div class=\"lev1 toc-item\"><a href=\"#Topic-Modelling\" data-toc-modified-id=\"Topic-Modelling-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Topic Modelling</a></div><div class=\"lev1 toc-item\"><a href=\"#Manual-Annotation\" data-toc-modified-id=\"Manual-Annotation-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Manual Annotation</a></div><div class=\"lev1 toc-item\"><a href=\"#Further-information\" data-toc-modified-id=\"Further-information-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Further information</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an introduction to some algorithms used in text analysis. While I cannot define **what questions** a scholar can ask, I can and do describe here **what kind of information** about text some popular methods can deliver. From this, you need to draw on your own research interests and creativity..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will describe methods of finding words that are characteristic for a certain passage (\"tf/tdf\"), constructing fingerprints or \"wordclouds\" for passages that go beyond the most significant words (\"word vectors\").  Of course, an important resource in text analysis is the hermeneutic interpretation of the scholar herself, so I will present a method of adding manual annotations to the text, and finally I will also say something about possible approaches to working across languages.\n",
    "\n",
    "At the moment the following topics are still waiting to be discussed: grouping passages according to their similarity (\"clustering\"), and forming an idea about different contexts being treated in a passage (\"topic modelling\"). Some more prominent approaches in the areas that have been mentioned so far are \"collocation\" analyses and the \"word2vec\" tool; I would like add discussions of these at a later moment.\n",
    "\n",
    "\"Natural language processing\" in the strict sense, i.e. analyses that have an understanding of how a language works, with its grammar, different modes, times, cases and the like, are *not* going to be covered; this implies \"stylometric\" analyses. Nor are there any discussions of \"artificial intelligence\" approaches. Maybe these can be discussed at another occasion and on another page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For many of the steps discussed on this page there are ready-made tools and libraries, often with easy interfaces. But first, it is important to understand what these tools are **actually doing** and how their results are affected by the **selection of parameters** (that one can or cannot modify).\n",
    "\n",
    "And second, most of these tools expect the **input to be in some particular format**, say, a series of plaintext files in their own directory, a list of word/number)-pairs, a table or a series of integer (or floating point) numbers, etc. So, by understanding the process, you should be better prepared to provide your text to the tools in the most productive way.\n",
    "\n",
    "Finally, it is important to be aware of what information is **lost** at which point in the process. If the research requires so, one can then either look for a different tool or approach to this step (e.g. using an additional dimension in the list of words to keep both original and regularized word forms, or to remember the position of the current token in the original text), or one can compensate for the data loss (e.g. offering a lemmatised search to find occurrences after the analysis returns only normalised word forms)..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The programming language used in the following examples is called \"python\" and the tool used to get prose discussion and code samples together is called \"jupyter\". In jupyter, you have a \"notebook\" that you can populate with text or code and a program that pipes a nice rendering of the notebook to a web browser. In this notebook, in many places, the output that the code samples produce is printed right below the code itself. Sometimes this can be quite a lot of output and depending on your viewing environment you might have to scroll quite some way to get to the continuation of the discussion. You can save your notebook online (the current one is [here at github](https://github.com/awagner-mainz/notebooks/blob/master/gallery/TextProcessing_Solorzano.ipynb)) and there is an online service, nbviewer, able to render any notebook that it can access online. So chances are you are reading this present notebook at the web address [https://nbviewer.jupyter.org/github/awagner-mainz/notebooks/blob/master/gallery/TextProcessing_Solorzano.ipynb](https://nbviewer.jupyter.org/github/awagner-mainz/notebooks/blob/master/gallery/TextProcessing_Solorzano.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A final word about the elements of this notebook:\n",
    "\n",
    "<div class=\"alert alertbox alert-success\">At some points I am mentioning things I consider to be important decisions or take-away messages for scholarly readers. E.g. whether or not to insert certain artefacts into the very transcription of your text, what the methodological ramifications of a certain approach or parameter are, what the implications of an example solution are, or what a possible interpretation of a certain result might be. I am highlighting these things in a block like this one here or at least in <font color=\"green\">**green bold font**</font>.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alertbox alert-danger\">**NOTE:** As I have continued improving the notebook on the side of the source text, wordlists and other parameters, I could (for lack of time) not keep the prose description in synch. So while the actual descriptions still apply, the numbers that are mentioned in the prose (as where we have e.g. a \"table with 20 rows and 1.672 columns\"), they might no longer reflect the latest state of the sources, auxiliary files and parameters. I will try to update these as I get to it, but for now, you should take such numbers with a grain of salt and rely rather on the actual code and its diagnostic output. I apologize for the inconsistency.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As indicated above, before doing maths, language processing tools normally expect their input to be in a certain format. First of all, you have to have an input in the first place: Therefore, a scholar wishing to experiment with such methods should avail herself of the text that should be studied, as a full transcription. This can be done by transcribing it herself, using transcriptions that are available from elsewhere, or even from OCR. (Although in the latter case, the results depend of course on the quality of the OCR output.) Second, many tools get tripped up when formatting or bibliographical metainformation is included in their input. And since the approaches presented here are not concerned with a digital edition or any other form of true representation of the source, *markup* (e.g. for bold font, heading or note elements) should be *suppressed*. (Other tools accept marked up text and strip the formatting internally.) So you should try to get a copy of the text(s) you are working with in **plaintext** format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For another detail regarding these plain text files, we have to make a short excursus, because even with plain text, there are some important aspects to consider: As you surely know, computers understand number only and as you probably also know, the first standards to encode alphanumeric characters, like ASCII, in numbers were designed for teleprinters and the reduced character set of the english language. When more extraordinary characters, like *Umlauts* or *accents* were to be encoded, one had to rely on extra rules, of which - unfortunately - there have been quite a lot. These are called \"**encodings**\" and one of the more important set of such rules are the windows encodings (e.g. CP-1252), another one is called Latin-9/ISO 8859-15 (it differs from the older Latin-1 encoding among others by including the Euro sign). Maybe you have seen web pages with garbled *Umlauts* or other special characters, then that was probably because your browser interpreted the numbers according to an encoding different from the one that the webpage author used. Anyway, the point here is that there is another standard encompassing virtually all the special signs from all languages and for a few years now, it is also supported quite well by operating systems, programming languages and linguistic tools. This standard is called \"Unicode\" and the encoding you want to use is called **utf-8**. So when you export or import your texts, try to make sure that this is what is used. ([Here](https://unicode-table.com/) is a webpage with the complete unicode table - it is loaded incrementally, so make sure to scroll down in order to get an impression of what signs this standard covers. But on the other hand, it is so extensive that you don't want to scroll through all the table...)\n",
    "\n",
    "Especially when you are coming from a windows operating system, you might have to do some searching about how to export your text to utf-8 (at one point I could make a unicode plaintext export in wordpad, only to find out after some time of desperate debugging that it was utf-*16* that I had been given. Maybe you can still find the traces of my own conversion of such files to utf-8 below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alertbox alert-success\">Also, you should consider whether or not you can replace *abbreviations* with their expanded versions in your transcription. While at some points (e.g. when lemmatising), you can associate expansions to abbreviations, the whole processing is easier when words in the text are indeed words, and periods are rather sentence punctuation than abbreviation signs. Of course, this also depends on the effort you can spend on the text...</div>\n",
    "\n",
    "This section now describes how the plaintext can further be prepared for analyses: E.g. if you want to process the *distribution* of words in the text, the processing method has to have some notion of different places in the text -- normally you don't want to manage words according to their absolute position in the whole work (say, the 6.349th word and the 3.100th one), but according to their occurrence in a particular section (say, in the third chapter, without caring too much whether it is in the 13th or in the 643th position in this chapter). So, you partition the text into meaningful segments which you can then label, compare etc.\n",
    "\n",
    "Other preparatory work includes suppressing stopwords (like \"the\", \"is\", \"of\" in english) or making the tools manage different forms of the same word or different historical writings identically. Here is what falls under this category:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1. [Get fulltext](#GetFulltext)\n",
    "  2. [Segment source text](#SegmentSourceText) \n",
    "  3. [Read segments into Variable/List](#ReadSegmentsIntoVariable)\n",
    "  4. [Tokenising](#Tokenising)\n",
    "  5. [Stemming/Lemmatising](#StemmingLemmatising)\n",
    "  6. [Eliminate stopwords](#EliminateStopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get fulltext <a name=\"GetFulltext\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the examples given on this page, I am using a transcription of Juan de Solorzano's *De Indiarum Iure*, provided by Angela Ballone. Angela has inserted a special sequence of characters - \"€€€ - [&lt;Label for the section>]\" - at places where she felt that a new section or argument is beginning, so that we can segment the big source file into different sections each dealing with one particular argument. (Our first task.) But first, let's have a look at our big source file; it is in the folder \"Solorzano\" and is called **Sections_I.1_TA.txt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T10:32:44.096794Z",
     "start_time": "2017-11-10T10:32:44.090793Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['€€€ - [Book title]\\n',\n",
       " 'LIBER PRIMUS:\\n',\n",
       " 'In quo de personis, et servitiis Indorum.\\n',\n",
       " '  Caput Primum.\\n',\n",
       " '  De statu et libertate Indorum in communi; et de origine et damnatione servitii personalis eorum, quod sub tributorum colore iniuste ab aliquibus usurpatur.\\n',\n",
       " '€€€ - [Indians are free]\\n',\n",
       " '  Quae prioribus (1) illis libris scripsimus, quos nuper circa iustam harum Indiarum Occidentalium inquisitionem, acquisitionem, et retentionem luce donavimus, ea, ut ibidem advertimus, praestolantur, quae ad earundem gubernationem spectant. In quibus proponendis et exponendis, ut recto ordine procedatur, ab Indorum personis, earumque statu, et conditione initium capessemus; (2) quarum in omnibus iuris quaestionibus priorem, potioremque; inspectionem esse debere, optime docuit I.C. in l.2 D. de stat. hom. l. si quaeremus 6. D. de testam. l. quidam referunt 14. D. de iure codicil. § ult. Instit. de iur. natur. l.2 § post originem, de orig. iur.\\n',\n",
       " '  Et plane (3) ipsos Indos Naturali, ac Civili Iure inspecto, et seriis, ac repetitis Regum nostrorum iussionibus et schedulis liberos esse, et ut liberos tractari debere, satis luculenter probatum reliquimus in lib.3 prioris voluminis, c.7 per tot. et optime supponit elegantissimus P. Ioseph. ACOSTA lib.2 de procur. Ind. salut. c.7.pag.235 quem ibídem n.53 retulimus, et iterum graviter repetit lib.3.cap.17 sic inquiens: Atque inprimis Indos non esse servitute mulctatos, sed liberos prorsus, et sui iuris, ex iis, quae in lib.2 disputata sunt, summimus. Etenim et publicae leges ita statuunt, et consuetudo diuturna, et ratio constans, ac certa, quod qui nulla iniuria lacessunt, non possint reddi belli iure captivi.\\n',\n",
       " '  Sed cum rerum usus, et (4) mixtae iam, ac communis eorundem Indorum, et Hispanorum Reipublicae utilitas, et neccessitas, aliqua munia, sive servitia induxisse, aut etiam extorsisse videatur, quibus illi addici, et distribui coeperunt, quae isthaec, et qualia sint, et quatenus iuxta iuris regulas subsistere possint? Hoc libro sigillatim percurrere, et distinctis capitibus trutinare conabimur.\\n',\n",
       " '€€€ - [Definition of «servicios personales»]\\n']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the path to our file\n",
    "bigsourcefile = 'Solorzano/Sections_I.1_TA.txt'\n",
    "# We use a variable 'input' for keeping its contents.\n",
    "input = open(bigsourcefile, encoding='utf-8').readlines()\n",
    "\n",
    "# Just for information, let's see the first 10 lines of the file.\n",
    "input[0:10]   # actually, since python starts counting with '0', we get 11 lines.\n",
    "             # and since there is no line wrapping in the source file,\n",
    "             # a line can be quite long.\n",
    "             # You can see the lines ending with a \"newline\" character \"\\n\" in the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment source text<a name=\"SegmentSourceText\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, as mentioned above, we want to associate information with only passages of the text, not the text as a whole. Therefore, the text has to be segmented. The one big single file is being split into meaningful smaller chunks. What exactly constitutes a meaningful chunk -- a chapter, an article, a paragraph etc. -- cannot be known independently of the text in question and of the research questions. Therefore, a typical approach is that the scholar either splits the text manually or inserts some symbols that otherwise do not appear in the text. This is what we have here. Then, processing tools can find these symbols and split the file accordingly. For keeping things neat and orderly, the resulting files are saved in a directory of their own..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(Note here and in the following that in most cases, when the program is counting, it does so beginning with zero. Which means that if we end up with 20 segments, they are going to be called segment_0.txt, segment_1,txt, ..., segment_19.txt. There is not going to be a segment bearing the number twenty, although we do have twenty segments. The first one has the number zero and the twentieth one has the number nineteen. Even for more experienced coders, this sometimes leads to mistakes, called \"off-by-one errors\".)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T10:32:48.743391Z",
     "start_time": "2017-11-10T10:32:48.741391Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 files written.\n"
     ]
    }
   ],
   "source": [
    "# folder for the several segment files:\n",
    "outputBase = 'Solorzano/segment'\n",
    "\n",
    "# initialise some variables:\n",
    "at    = -1\n",
    "dest  = None                  # this later takes our destination files\n",
    "\n",
    "# Now, for every line, if it starts with our special string,\n",
    "#    do nothing with the line,\n",
    "#    but close the current and open the next destination file;\n",
    "# if it does not,\n",
    "#   append it to whatever is the current destination file\n",
    "#   (stripping leading and trailing whitespace).\n",
    "for line in input:\n",
    "    if line[0:3] == '€€€':\n",
    "        # if there is a file open, then close it\n",
    "        if dest:\n",
    "            dest.close()\n",
    "        at += 1\n",
    "        # open the next destination file for writing\n",
    "        # (It's filename is build from our outputBase variable,\n",
    "        #  the current position in the sequence of fragments,\n",
    "        #  and a \".txt\" ending)\n",
    "        dest = open(outputBase + '.' + str(at) + '.txt',\n",
    "                    encoding='utf-8',\n",
    "                    mode='w')\n",
    "    else:\n",
    "        # write the line (after it has been stripped of leading and closing whitespace)\n",
    "        dest.write(line.strip())\n",
    "\n",
    "dest.close()\n",
    "at += 1\n",
    "\n",
    "# How many segments/files do we then have?\n",
    "print(str(at) + ' files written.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read segments into a variable <a name=\"ReadSegmentsIntoVariable\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the segments just created, we rebuild our corpus, iterating through them and reading them into another variable (which now stores, technically speaking, not just one long string of characters, as the variable *input* in the first code snippet did, but a list of strings, one for each segment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T10:32:51.797243Z",
     "start_time": "2017-11-10T10:32:51.796243Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'Solorzano'\n",
    "filename = 'segment.'\n",
    "suffix = '.txt'\n",
    "corpus = []           # This is our new variable. It will be populated below.\n",
    "\n",
    "for i in range(0, at):\n",
    "    with open(path + '/' + filename + str(i) + suffix, encoding='utf-8') as f:\n",
    "        corpus.append(f.read())    # Here, a new element is added to our corpus.\n",
    "                                       # Its content is read from the file 'f' opened above\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should have 20 strings in the variable *corpus* to play around with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T10:32:54.694466Z",
     "start_time": "2017-11-10T10:32:54.693466Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a quick impression, let's see the opening 500 characters of an arbitrary one of them; in this case, we take the fourth segment, i.e. the one at position '3' (remember that counting starts at 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T10:32:57.131065Z",
     "start_time": "2017-11-10T10:32:57.129064Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hoc autem servitium (6) inde (ut apparet) originem habuit, quod cum principio detectionis harum regionum, Indi Hispanis commendari coepissent, ut illos protegerent, et in Fide Catholica diligenter instruerent, et huius curae ratione Indi ipsi certum illis pensum, sive tributum praestare iuberentur (de quo inferius secundo Libro plenius agemus) eiusmodi Hispani, qui ita Indos in commendam acceperant, tributi loco, plenam in eos, et eorum bona dominationem usurparunt, nullum opus, quantumvis durum'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[3][0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenising <a name=\"Tokenising\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Tokenising\" means splitting the long lines of the input into single words. Since we are dealing with plain latin, we can use the default split method which relies on spaces to identify word boundaries. (In languages like Japanese or scripts like Arabic, this is more difficult.) **Note that we do not compensate for words that are hyphenated/split across lines here!** That is something that should be catered for in the transcription itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T10:32:59.764288Z",
     "start_time": "2017-11-10T10:32:59.762288Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We now have 4208 wordforms or \"tokens\" in our corpus of 20 segments.\n"
     ]
    }
   ],
   "source": [
    "# We need a python library, because we want to use a \"regular expression\"\n",
    "import re\n",
    "\n",
    "tokenised = []     # A new variable again\n",
    "\n",
    "# Every segment, initially a long string of characters, is now split into a list of words,\n",
    "# based on non-word characters (whitespace, punctuation, parentheses and others - that's\n",
    "# what we need the regular expression library for).\n",
    "# Also, we make everything lower-case.\n",
    "for segment in corpus:\n",
    "    tokenised.append(list(filter(None, (word.lower() for word in re.split('\\W+', segment)))))\n",
    "\n",
    "print('We now have ' + str(sum(len(x) for x in tokenised)) + ' wordforms or \"tokens\" in our corpus of ' + str(len(tokenised)) + ' segments.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of *corpus*, we can use *tokenised* for our subsequent routines: a variable which, at 20 positions, contains the list of words of the corresponding segment. In order to see the difference in structure to the corpus variable above, let's have a look at (the first 50 words of) the fourth segment again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T10:33:02.321296Z",
     "start_time": "2017-11-10T10:33:02.319296Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hoc', 'autem', 'servitium', '6', 'inde', 'ut', 'apparet', 'originem', 'habuit', 'quod', 'cum', 'principio', 'detectionis', 'harum', 'regionum', 'indi', 'hispanis', 'commendari', 'coepissent', 'ut', 'illos', 'protegerent', 'et', 'in', 'fide', 'catholica', 'diligenter', 'instruerent', 'et', 'huius', 'curae', 'ratione', 'indi', 'ipsi', 'certum', 'illis', 'pensum', 'sive', 'tributum', 'praestare', 'iuberentur', 'de', 'quo', 'inferius', 'secundo', 'libro', 'plenius', 'agemus', 'eiusmodi']\n"
     ]
    }
   ],
   "source": [
    "print(tokenised[3][0:49])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already, we can have a first go at finding the most frequent words for a segment. (For this we use a simple library of functions that we import by the name of 'collections'.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T10:33:05.187738Z",
     "start_time": "2017-11-10T10:33:05.186738Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('et', 7), ('in', 5), ('indi', 3), ('non', 3), ('hoc', 2), ('ut', 2), ('quod', 2), ('illis', 2), ('pensum', 2), ('de', 2)]\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "counter = collections.Counter(tokenised[3])  # Again, consider the fourth segment\n",
    "print(counter.most_common(10))               # Making a counter 'object' of our segment,\n",
    "                                             # this now has a 'method' calles most_common,\n",
    "                                             # offering us the object's most common elements.\n",
    "                                             # More 'methods' can be found in the documentation:\n",
    "                                             # https://docs.python.org/3/library/collections.html#collections.Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nicer layout: tables instead of lists of tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps now is a good opportunity for another small excursus. What we have printed in the last code is a series of pairs: Words associated to their number of occurrences, sorted by the latter. This is called a \"dictionary\" in python. However, the display looks a bit ugly. With another library called \"pandas\" (for \"python data analysis\"), we can make this look more intuitive. (Of course, your system must have this library installed in the first place so that we can import it in our code.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T10:33:08.348197Z",
     "start_time": "2017-11-10T10:33:07.955167Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>et</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>in</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>indi</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>non</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>quod</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>tributi</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>eos</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hoc</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>vel</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ut</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lemma  count\n",
       "21        et      7\n",
       "22        in      5\n",
       "15      indi      3\n",
       "72       non      3\n",
       "9       quod      2\n",
       "52   tributi      2\n",
       "55       eos      2\n",
       "0        hoc      2\n",
       "112      vel      2\n",
       "5         ut      2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.DataFrame.from_dict(counter, orient='index').reset_index() # from our counter object,\n",
    "                                                                    # we now make a DataFrame object\n",
    "df2 = df1.rename(columns={'index':'lemma',0:'count'})               # and we name our columns\n",
    "\n",
    "df2.sort_values('count',0,False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks better now, doesn't it?\n",
    "\n",
    "_(The bold number in the very first column is the id as it were of the respective lemma. You see that 'hoc' has the id '0' - because it was the first word that occurred at all -, and 'ut' has the id '5' because it was the sixth word in our segment. Most probably, currently we are not interested in the position of the word and can ignore the first column.)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming / Lemmatising <a name=\"StemmingLemmatising\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, since we prefer to count different word *forms* as one and the same \"*lemma*\", we have to do a step called \"lemmatisation\". In languages that are not strongly inflected, like English, one can get away with \"stemming\", i.e. just eliminating the ending of words: \"wish\", \"wished\", \"wishing\", \"wishes\" all can count as instances of \"wish\\*\". With Latin this is not so easy: we want to count occurrences of \"legum\", \"leges\", \"lex\" as one and the same word, but if we truncate after \"le\", we get too many hits that have nothing to do with lex at all. There are a couple of \"lemmatising\" tools available, although with classical languages (or even early modern ones), it's a bit more difficult. Anyway, we do our own, using a dictionary approach..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to have a dictionary which associates all known word forms to their lemma. This can also help us with historical orthography. Suppose from some other context, we have a file \"[wordforms-lat.txt](Solorzano/wordforms-lat.txt)\" at our disposal in the \"Solorzano\" folder. Its contents looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:42.499828Z",
     "start_time": "2017-11-10T11:14:42.406819Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aër > aër\n",
      "aëre > aër\n",
      "aërem > aër\n",
      "aëri > aër\n",
      "aëris > aër\n",
      "a > a\n",
      "ab\n"
     ]
    }
   ],
   "source": [
    "wordfile_path = 'Solorzano/wordforms-lat-full.txt'\n",
    "wordfile = open(wordfile_path, encoding='utf-8')\n",
    "\n",
    "print(wordfile.read()[:64])     # in such from-to addresses, one can just skip the zero\n",
    "wordfile.close;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we again build a dictionary of key-value pairs associating all the lemmata (\"values\") with their wordforms (\"keys\"). And afterwards, we can quickly look up the value under a given key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:45.775156Z",
     "start_time": "2017-11-10T11:14:42.585837Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2131211 wordforms known to the system.\n"
     ]
    }
   ],
   "source": [
    "lemma    = {}    # we build a so-called dictionary for the lookups\n",
    "tempdict = []\n",
    "\n",
    "# open the wordfile (defined above) for reading\n",
    "wordfile = open(wordfile_path, encoding='utf-8')\n",
    "\n",
    "for line in wordfile.readlines():\n",
    "    tempdict.append(tuple(line.split('>'))) # we split each line by \">\" and append a tuple to a\n",
    "                                            # temporary list.\n",
    "\n",
    "lemma = {k.strip(): v.strip() for k, v in tempdict} # for every tuple in the list,\n",
    "                                                    # we strip whitespace and make a key-value\n",
    "                                                    # pair, appending it to our \"lemma\" dictionary\n",
    "wordfile.close\n",
    "print(str(len(lemma)) + ' wordforms known to the system.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, a quick test: Let's see with which \"lemma\"/basic word the particular wordform \"ciuicior\" is associated, or, in other words, what *value* our lemma variable returns when we query for the *key* \"ciuicior\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:45.779156Z",
     "start_time": "2017-11-10T11:14:45.776156Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fides'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma['fidem']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use this dictionary to build a new list of words, where only lemmatised forms occur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:45.866165Z",
     "start_time": "2017-11-10T11:14:45.780156Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For each segment, and for each word in it, add the lemma to our new \"lemmatised\"\n",
    "# list, or, if we cannot find a lemma, add the actual word from from the tokenised list.\n",
    "lemmatised = [[lemma[word] if word in lemma else word for word in segment]\n",
    "              for segment in tokenised]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's see the first 50 words from the fourth segment, and compare them with the \"tokenised\" variant above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:45.957174Z",
     "start_time": "2017-11-10T11:14:45.867165Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hic', 'autem', 'servitium', '6', 'inde', 'ut', 'appareo', 'origo', 'habeo', 'qui', 'cum', 'principium', 'detectio', 'hic', 'regio', 'indios', 'hispanis', 'commendo', 'coepio', 'ut', 'ille', 'protego', 'et', 'in', 'fides', 'catholicus', 'diligens', 'instruo', 'et', 'hic', 'cura', 'ratio', 'indios', 'ipse', 'certus', 'ille', 'pendo', 'sive', 'tribuo', 'praesto', 'iubeo', 'de', 'qui', 'inferius', 'secundo', 'liber', 'plenus', 'ago', 'eiusmodi']\n"
     ]
    }
   ],
   "source": [
    "print(lemmatised[3][:49])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the original text is lost now from the data that we are currently working with (unless we add another dimension to our lemmatised variable which can keep the original word form). But let us see if something in the 10 most frequent words has changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:46.055184Z",
     "start_time": "2017-11-10T11:14:45.958174Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>et</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>in</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>qui</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>indios</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ille</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>nolo</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>is</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>tribuo</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>plenus</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lemma  count\n",
       "20      et      7\n",
       "21      in      5\n",
       "0      hic      4\n",
       "9      qui      4\n",
       "14  indios      4\n",
       "18    ille      3\n",
       "64    nolo      3\n",
       "48      is      3\n",
       "32  tribuo      3\n",
       "39  plenus      2"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter2 = collections.Counter(lemmatised[3])\n",
    "df1 = pd.DataFrame.from_dict(counter2, orient='index').reset_index()\n",
    "df2 = df1.rename(columns={'index':'lemma',0:'count'})\n",
    "\n",
    "df2.sort_values('count',0,False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, things have changed: \"tributum\" has moved one place up, \"non\" is now counted as \"nolo\" (I am not sure this makes sense, but such is the dictionary of wordforms we have used) and \"pensum\" has now made it on the list!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminate Stopwords <a name=\"EliminateStopwords\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably \"et\", \"in\", \"de\", \"qui\", \"ad\", \"sum/esse\", \"non/nolo\" and many of the most frequent words are not really very telling words. They are what one calls *stopwords*, and we have another [list of such words](Solorzano/stopwords-lat.txt) that we would rather want to ignore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:46.157194Z",
     "start_time": "2017-11-10T11:14:46.056184Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388 stopwords known to the system, e.g.: ['a', 'ab', 'ac', 'ad', 'adhic', 'adhuc', 'ae', 'ait', 'ali', 'alii', 'aliis', 'alio', 'aliqua', 'aliqui', 'aliquid', 'aliquis', 'aliquo', 'am', 'an', 'ante', 'apud', 'ar', 'at', 'atque', 'au', 'aut', 'autem', 'bus', 'c', 'ca', 'cap', 'ceptum', 'co', 'con', 'cons', 'cui', 'cum', 'cur', 'cùm', 'd', 'da', 'de', 'deinde', 'detur', 'di', 'diu', 'do', 'dum', 'e', 'ea', 'eadem', 'ec', 'eccle', 'ego', 'ei', 'eis', 'eius', 'el', 'em', 'en', 'enim', 'eo', 'eos', 'er', 'erat', 'ergo', 'erit', 'es', 'esse', 'essent', 'esset', 'est', 'et', 'etenim', 'eti']\n"
     ]
    }
   ],
   "source": [
    "stopwords_path = 'Solorzano/stopwords-lat.txt'\n",
    "stopwords = open(stopwords_path, encoding='utf-8').read().splitlines()\n",
    "\n",
    "print(str(len(stopwords)) + ' stopwords known to the system, e.g.: ' + str(stopwords[95:170]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try and suppress the stopwords in the segments (and see what the \"reduced\" fourth segment gives)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:46.269205Z",
     "start_time": "2017-11-10T11:14:46.158194Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['servitium', 'inde', 'appareo', 'origo', 'principium', 'detectio', 'regio', 'indios', 'hispanis', 'commendo', 'coepio', 'protego', 'fides', 'catholicus', 'diligens', 'instruo', 'cura', 'ratio', 'indios', 'certus', 'pendo', 'tribuo', 'praesto', 'iubeo', 'inferius', 'secundo', 'liber', 'plenus', 'ago', 'eiusmodi', 'hispani', 'queo', 'indios', 'commendam', 'accipio', 'tribuo', 'loco', 'plenus', 'bonum', 'dominatio', 'usurpo', 'nullus', 'opus', 'quantumvis', 'durus', 'laboriosus', 'praetermitto', 'tamquam', 'serva']\n"
     ]
    }
   ],
   "source": [
    "# For each segment, and for each word in it,\n",
    "# add it to a new list called \"stopped\",\n",
    "# but only if it is not listed in the list of stopwords.\n",
    "stopped = [[item for item in lemmatised_segment if item not in stopwords] \\\n",
    "           for lemmatised_segment in lemmatised]\n",
    "print(stopped[3][:49])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can already create a kind of first \"profile\" of, say, our first six segments, listing the most frequent words in each of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:46.350213Z",
     "start_time": "2017-11-10T11:14:46.270205Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Most frequent lemmata in the first text segment (segment number zero):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>servitium</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indios</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liber</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prior</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>persona</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>caput</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sisto</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>libertas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>commune</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>origo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lemma  count\n",
       "3  servitium      2\n",
       "4     indios      2\n",
       "0      liber      1\n",
       "1      prior      1\n",
       "2    persona      1\n",
       "5      caput      1\n",
       "6      sisto      1\n",
       "7   libertas      1\n",
       "8    commune      1\n",
       "9      origo      1"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter3 = collections.Counter(stopped[0])\n",
    "df0_1 = pd.DataFrame.from_dict(counter3, orient='index').reset_index()\n",
    "df0_2 = df0_1.rename(columns={'index':'lemma',0:'count'})\n",
    "print(' Most frequent lemmata in the first text segment (segment number zero):')\n",
    "df0_2.sort_values(by='count',axis=0,ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:46.441222Z",
     "start_time": "2017-11-10T11:14:46.351213Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Most frequent lemmata in the second text segment (segment number one):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ius</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>liber</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>indios</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prior</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>repeto</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>refero</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>iur</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>debeo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>bonus</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>gravis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lemma  count\n",
       "31     ius      6\n",
       "1    liber      5\n",
       "23  indios      4\n",
       "0    prior      3\n",
       "55  repeto      2\n",
       "43  refero      2\n",
       "47     iur      2\n",
       "35   debeo      2\n",
       "36   bonus      2\n",
       "76  gravis      1"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter4 = collections.Counter(stopped[1])\n",
    "df1_1 = pd.DataFrame.from_dict(counter4, orient='index').reset_index()\n",
    "df1_2 = df1_1.rename(columns={'index':'lemma',0:'count'})\n",
    "print(' Most frequent lemmata in the second text segment (segment number one):')\n",
    "df1_2.sort_values(by='count',axis=0,ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:46.531231Z",
     "start_time": "2017-11-10T11:14:46.442222Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Most frequent lemmata in the third text segment:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>servitium</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>personalis</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>soleo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>utilitas</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>indios</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>contemplatio</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>liber</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>gravo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>persona</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>commodum</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lemma  count\n",
       "0      servitium      2\n",
       "1     personalis      2\n",
       "7          soleo      2\n",
       "8       utilitas      2\n",
       "9         indios      2\n",
       "45  contemplatio      1\n",
       "51         liber      1\n",
       "50         gravo      1\n",
       "49       persona      1\n",
       "48      commodum      1"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter5 = collections.Counter(stopped[2])\n",
    "df2_1 = pd.DataFrame.from_dict(counter5, orient='index').reset_index()\n",
    "df2_2 = df2_1.rename(columns={'index':'lemma',0:'count'})\n",
    "print(' Most frequent lemmata in the third text segment:')\n",
    "df2_2.sort_values(by='count',axis=0,ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:46.622240Z",
     "start_time": "2017-11-10T11:14:46.532231Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Most frequent lemmata in the fourth text segment:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>indios</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tribuo</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>praesto</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>iubeo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>plenus</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pendo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>certus</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>species</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>quidam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>designo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lemma  count\n",
       "7    indios      4\n",
       "20   tribuo      3\n",
       "21  praesto      2\n",
       "22    iubeo      2\n",
       "26   plenus      2\n",
       "19    pendo      2\n",
       "18   certus      2\n",
       "55  species      1\n",
       "59   quidam      1\n",
       "58  designo      1"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter6 = collections.Counter(stopped[3])\n",
    "df3_1 = pd.DataFrame.from_dict(counter6, orient='index').reset_index()\n",
    "df3_2 = df3_1.rename(columns={'index':'lemma',0:'count'})\n",
    "print(' Most frequent lemmata in the fourth text segment:')\n",
    "df3_2.sort_values(by='count',axis=0,ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay, look here, we have our words \"indis\", \"tributum\", \"pensum\" from the top ten above again, but this time the non-significant (for our present purposes) words in-between have been eliminated. Instead, new words like \"numerata\", \"operis\" etc. have made it into the top ten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:46.722250Z",
     "start_time": "2017-11-10T11:14:46.623241Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Most frequent lemmata in the fifth text segment:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>personalis</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>servitium</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>indios</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>anno</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>queo</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>alea</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>semi</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>tribuo</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>eodem</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>novo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lemma  count\n",
       "0   personalis      6\n",
       "1    servitium      5\n",
       "72      indios      5\n",
       "30        anno      4\n",
       "38        queo      4\n",
       "79        alea      4\n",
       "32        semi      4\n",
       "85      tribuo      3\n",
       "34       eodem      3\n",
       "73        novo      2"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter7 = collections.Counter(stopped[4])\n",
    "df4_1 = pd.DataFrame.from_dict(counter7, orient='index').reset_index()\n",
    "df4_2 = df4_1.rename(columns={'index':'lemma',0:'count'})\n",
    "print(' Most frequent lemmata in the fifth text segment:')\n",
    "df4_2.sort_values(by='count',axis=0,ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:46.814260Z",
     "start_time": "2017-11-10T11:14:46.723251Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Most frequent lemmata in the sixth text segment:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>regnum</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>alea</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anno</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>personalis</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>servitium</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>nosco</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>accipio</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>servicio</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>indios</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>peruanum</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lemma  count\n",
       "11       regnum      5\n",
       "78         alea      5\n",
       "1          anno      4\n",
       "64   personalis      3\n",
       "68    servitium      3\n",
       "104       nosco      2\n",
       "25      accipio      2\n",
       "34     servicio      2\n",
       "40       indios      2\n",
       "12     peruanum      2"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter8 = collections.Counter(stopped[5])\n",
    "df5_1 = pd.DataFrame.from_dict(counter8, orient='index').reset_index()\n",
    "df5_2 = df5_1.rename(columns={'index':'lemma',0:'count'})\n",
    "print(' Most frequent lemmata in the sixth text segment:')\n",
    "df5_2.sort_values(by='count',axis=0,ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alertbox alert-success\">So far our initial analyses, then. There are several ways in which we can continue now. We see that there are still word (like 'damnatione', tributorum' in the first or 'statuunt' in the second segment) that are not covered by our lemmatisation process. Also, abbreviations (like 'iur' in the second segment) could be expanded either in the transcription or by adding an appropriate line in our list of lemmata. Words like 'dom' in the fifth segment could maybe be added to the list of stopwords? Anyway, more need for review of these two lists (lemmata/stopwords) is explained below and that is something that should definitely be done - after all, they were taken from the context of quite another project and a scholar should control closely  what is being suppressed and what is being replaced in the text under hand.</div>\n",
    "\n",
    "<div class=\"alert alertbox alert-success\">But we could also do more sophisticated things with the list. We could e.g. use either our lemma list or our stopwords list to filter out certain words, like all non-substantives. Or we could reduce all mentions of a certain name or literary work to a specific form (that would be easily recognizable in all the places).</div>\n",
    "\n",
    "However, we can already observe that meaningful words like \"indios/indis\" are maybe not so helpful in characterising individual passages of this work, since they occur all over the place. After all, the work is called \"De Indiarum Iure\" and deals with various questions all related to indigenous people. Also, we would like to give some weight to the fact that a passage may consist of all stopwords and perhaps one or two substantial words, whereas another might be full of substantial words and few stopwords only (think e.g. of an abstract or an opening chapter describing the rest of the work). Or, since we have text segments of varying length, we would like our figures to reflect the fact that a tenfold occurrence in a very short passage may be more significant than a tenfold occurrence in a very, very, very long passage.\n",
    "\n",
    "These phenomena are treated with more mathematical tools, so let's say that our preparatory work is done ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterise passages: TF/IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described, we are now going to delve a wee bit deeper into mathematics in order to get more precise characterizations of our text segments. The approach we are going to use is called \"TF/IDF\" and is a simple, yet powerful method that is very popular in text mining and search engine discussions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1. [Build vocabulary](#BuildVocabulary)\n",
    "  2. [Calculate Terms' Text Frequencies (TF)](#CalculateTF) \n",
    "  3. [Normalise TF](#NormaliseTF)\n",
    "  4. [Inverse Document Frequencies (IDF) and TF-IDF](#CalculateTFIDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build vocabulary <a name=\"BuildVocabulary\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since maths works best with numbers, let's first of all build a list of all the words (in their basic form) that occur anywhere in the text, and give each one of those words an ID (say, the position of its first occurrence in the work):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:46.908269Z",
     "start_time": "2017-11-10T11:14:46.815260Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1309 distinct words in the corpus:\n",
      "['1542', '1549', '1555', '1563', '1568', '1581', '1591', '1595', '1601', '1604', '1609', '1610', '1617', '1620', '1639', '342', '43', '550', 'abb', 'aboleo', 'absolvo', 'absque', 'abutor', 'accipio', 'acost', 'acosta', 'acquisitio', 'act', 'act_non_detur', 'actio', 'actum', 'ad_leg', 'addico', 'addo', 'adduco', 'adelante', 'administratio', 'admodum', 'adscriptitiis', 'adversus', 'adverto', 'aedifico', 'aequum', 'aestimo', 'aetas', 'afflictus', 'affligo', 'africae', 'africanos', 'ager', 'agero', 'agia', 'ago', 'agric', 'alban', 'albano', 'alea', 'alguno', 'alibi', 'alieno', 'aliquot', 'alium', 'alius', 'alivio', 'allec', 'allego', 'aloe', 'alphan', 'alt', 'alter', 'ambigo', 'andr', 'angel', 'ann', 'anno', 'annua', 'annus', 'ant', 'antiqua', 'antiquus', 'aperio', 'apostolicus', 'appareo', 'appell', 'appello', 'applico', 'aqaeductu', 'aquí', 'aranjuecii', 'arceo', 'archid', 'ardens', 'arequipensi', 'argentina', 'argumentum', 'art', 'ascribo', 'assero', 'asservio', 'assigno']\n"
     ]
    }
   ],
   "source": [
    "# We can use a library function for this\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Since the library function can do all of the above (splitting, tokenising, lemmatising),\n",
    "# and since it is providing hooks for us to feed our own tokenising, lemmatising and stopwords\n",
    "# resources or functions to it,\n",
    "# we use it and work on our rather raw \"corpus\" variable from way above again.\n",
    "\n",
    "# So first we build a tokenising and lemmatising function to work as an input filter\n",
    "# to the CountVectorizer function\n",
    "def ourLemmatiser(str_input):\n",
    "    wordforms = re.split('\\W+', str_input)\n",
    "    return [lemma[wordform].lower().strip() if wordform in lemma else wordform.lower().strip() for wordform in wordforms ]\n",
    "\n",
    "# Then we initialize the CountVectorizer function to use our stopwords and lemmatising fct.\n",
    "count_vectorizer = CountVectorizer(tokenizer=ourLemmatiser, stop_words=stopwords)\n",
    "\n",
    "# Finally, we feed our corpus to the function, building a new \"vocab\" object\n",
    "vocab = count_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Print some results\n",
    "print(str(len(count_vectorizer.get_feature_names())) + ' distinct words in the corpus:')\n",
    "print(count_vectorizer.get_feature_names()[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how our corpus of four thousand \"tokens\" actually contains only one and a half thousand different words (plus stopwords, but these are at maximum 384). And, in contrast to simpler numbers that have been filtered out by our stopwords filter, I have left years like \"1610\" in place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Terms' Text Frequencies (TF) <a name=\"CalculateTF\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, our \"vocab\" object contains more than just all the unique words in our corpus. Let's get some information about it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:46.999278Z",
     "start_time": "2017-11-10T11:14:46.994278Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20x1309 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2019 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is actually a table with 20 rows (the number of our segments) and 1.672 columns (the number of unique words in the corpus). So what we do have is a table where for each segment the amount of occurrences of every \"possible\" (in the sense of used somewhere in the corpus) word is listed.\n",
    "\n",
    "*(\"Sparse\" means that the majority of fields is zero. And 2.142 fields are populated, which is more than the number of unique words in the corpus (1.672, see above) - that's obviously because some words occur in multiple segments = rows. Not much of a surprise, actually.)*\n",
    "\n",
    "Here is the whole table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:47.322310Z",
     "start_time": "2017-11-10T11:14:47.295308Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1542</th>\n",
       "      <th>1549</th>\n",
       "      <th>1555</th>\n",
       "      <th>1563</th>\n",
       "      <th>1568</th>\n",
       "      <th>1581</th>\n",
       "      <th>1591</th>\n",
       "      <th>1595</th>\n",
       "      <th>1601</th>\n",
       "      <th>1604</th>\n",
       "      <th>...</th>\n",
       "      <th>voluntad</th>\n",
       "      <th>voluntarius</th>\n",
       "      <th>vos</th>\n",
       "      <th>vot</th>\n",
       "      <th>votum</th>\n",
       "      <th>vulgatus</th>\n",
       "      <th>vulgo</th>\n",
       "      <th>words1</th>\n",
       "      <th>zalsius</th>\n",
       "      <th>zassi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 1309 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    1542  1549  1555  1563  1568  1581  1591  1595  1601  1604  ...    \\\n",
       "0      0     0     0     0     0     0     0     0     0     0  ...     \n",
       "1      0     0     0     0     0     0     0     0     0     0  ...     \n",
       "2      0     0     0     0     0     0     0     0     0     0  ...     \n",
       "3      0     0     0     0     0     0     0     0     0     0  ...     \n",
       "4      1     1     1     1     0     0     0     0     0     1  ...     \n",
       "5      0     0     0     0     1     1     1     1     0     0  ...     \n",
       "6      0     0     0     0     0     0     0     0     1     0  ...     \n",
       "7      0     0     0     0     0     0     0     0     1     0  ...     \n",
       "8      0     0     0     0     0     0     0     0     0     0  ...     \n",
       "9      0     0     0     0     0     0     0     0     0     0  ...     \n",
       "10     0     0     0     0     1     0     0     0     0     0  ...     \n",
       "11     0     0     0     0     0     0     0     0     0     0  ...     \n",
       "12     0     0     0     0     0     0     0     0     0     0  ...     \n",
       "13     0     0     0     0     0     0     0     0     0     0  ...     \n",
       "14     0     0     0     0     0     0     0     0     1     0  ...     \n",
       "15     0     0     0     0     0     0     0     0     0     0  ...     \n",
       "16     0     0     0     0     0     0     0     0     0     0  ...     \n",
       "17     0     0     0     0     0     0     0     0     0     0  ...     \n",
       "18     0     0     0     0     0     0     0     0     0     0  ...     \n",
       "19     0     0     0     0     0     0     0     0     0     0  ...     \n",
       "\n",
       "    voluntad  voluntarius  vos  vot  votum  vulgatus  vulgo  words1  zalsius  \\\n",
       "0          0            0    0    0      0         0      0       0        0   \n",
       "1          0            0    0    0      0         0      0       0        0   \n",
       "2          0            0    0    0      0         0      0       0        0   \n",
       "3          0            0    0    0      0         0      0       0        0   \n",
       "4          1            0    0    0      0         0      0       0        0   \n",
       "5          0            0    0    0      0         0      0       0        0   \n",
       "6          1            1    0    0      0         0      1       0        0   \n",
       "7          0            0    0    0      1         0      0       0        0   \n",
       "8          0            0    0    0      0         0      0       0        0   \n",
       "9          0            0    0    0      0         0      0       0        1   \n",
       "10         0            0    0    0      0         0      0       0        0   \n",
       "11         0            0    0    0      0         0      0       0        0   \n",
       "12         0            0    0    0      0         0      0       0        0   \n",
       "13         0            0    0    0      0         0      0       0        0   \n",
       "14         0            0    0    0      0         0      0       0        0   \n",
       "15         0            0    0    0      0         0      0       0        0   \n",
       "16         0            0    1    1      0         0      0       0        0   \n",
       "17         0            0    0    0      0         0      0       0        0   \n",
       "18         0            0    0    0      0         1      0       0        0   \n",
       "19         0            0    0    0      0         0      0       1        0   \n",
       "\n",
       "    zassi  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "5       0  \n",
       "6       0  \n",
       "7       0  \n",
       "8       0  \n",
       "9       1  \n",
       "10      0  \n",
       "11      0  \n",
       "12      0  \n",
       "13      0  \n",
       "14      0  \n",
       "15      0  \n",
       "16      0  \n",
       "17      0  \n",
       "18      0  \n",
       "19      0  \n",
       "\n",
       "[20 rows x 1309 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(vocab.toarray(), columns=count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row of this table is a kind of fingerprint of a segment: We don't know the order of words in the segment - for us, it is just a \"*bag of words*\" -, but we know which words occur in the segment and how often they do. But as of now, it is a rather bad fingerprint, because how significant a certain number of occurences of a word in a segment is depends on the actual length of the segment. Ignorant as we are (per assumption) of the role and meaning of those words, still, if a word occurs twice in a short paragraph, that should *prima facie* count as more characteristic of the paragraph than if it occurs twice in a multi-volume work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalise TF <a name=\"NormaliseTF\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reflect this if we divide the number of occurrences of a word by the number of tokens in the segment. Obviously the number will then be quite small - but what counts is the relations between the cells and we can account for scaling and normalizing later...\n",
    "\n",
    "We're almost there and we are switching from the CountVectorizer function to another one, that does the division just mentioned and will do more later on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:48.058384Z",
     "start_time": "2017-11-10T11:14:48.015380Z"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1542</th>\n",
       "      <th>1549</th>\n",
       "      <th>1555</th>\n",
       "      <th>1563</th>\n",
       "      <th>1568</th>\n",
       "      <th>1581</th>\n",
       "      <th>1591</th>\n",
       "      <th>1595</th>\n",
       "      <th>1601</th>\n",
       "      <th>1604</th>\n",
       "      <th>...</th>\n",
       "      <th>voluntad</th>\n",
       "      <th>voluntarius</th>\n",
       "      <th>vos</th>\n",
       "      <th>vot</th>\n",
       "      <th>votum</th>\n",
       "      <th>vulgatus</th>\n",
       "      <th>vulgo</th>\n",
       "      <th>words1</th>\n",
       "      <th>zalsius</th>\n",
       "      <th>zassi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.013889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 1309 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1542      1549      1555      1563      1568      1581      1591  \\\n",
       "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4   0.003717  0.003717  0.003717  0.003717  0.000000  0.000000  0.000000   \n",
       "5   0.000000  0.000000  0.000000  0.000000  0.005291  0.005291  0.005291   \n",
       "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "8   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "10  0.000000  0.000000  0.000000  0.000000  0.005051  0.000000  0.000000   \n",
       "11  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "12  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "13  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "14  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "15  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "16  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "17  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "18  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "19  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        1595      1601      1604    ...     voluntad  voluntarius       vos  \\\n",
       "0   0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "1   0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "2   0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "3   0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "4   0.000000  0.000000  0.003717    ...     0.003717     0.000000  0.000000   \n",
       "5   0.005291  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "6   0.000000  0.006849  0.000000    ...     0.006849     0.006849  0.000000   \n",
       "7   0.000000  0.005051  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "8   0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "9   0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "10  0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "11  0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "12  0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "13  0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "14  0.000000  0.007353  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "15  0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "16  0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.007042   \n",
       "17  0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "18  0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "19  0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "\n",
       "         vot     votum  vulgatus     vulgo    words1   zalsius     zassi  \n",
       "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "5   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "6   0.000000  0.000000  0.000000  0.006849  0.000000  0.000000  0.000000  \n",
       "7   0.000000  0.005051  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "8   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.013889  0.013889  \n",
       "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "11  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "12  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "13  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "14  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "15  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "16  0.007042  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "17  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "18  0.000000  0.000000  0.013889  0.000000  0.000000  0.000000  0.000000  \n",
       "19  0.000000  0.000000  0.000000  0.000000  0.012195  0.000000  0.000000  \n",
       "\n",
       "[20 rows x 1309 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the library's function\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stopwords, use_idf=False, tokenizer=ourLemmatiser, norm='l1')\n",
    "\n",
    "# Finally, we feed our corpus to the function to build a new \"tf_matrix\" object\n",
    "tf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Print some results\n",
    "pd.DataFrame(tf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have seen above that \"indis\" is occurring in all of the segments, because, as the title indicates, the whole work is about issues related to the Indies and to indigenous people. When we want to characterize a segment by referring to some of its words, is there a way to weigh down words like \"indis\" a little bit? Not filter them out completely, as we do with stopwords, but give them just a little less weight than words not appearing all over the place? Yes there is..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Inverse Document Frequencies (IDF) and TF-IDF <a name=\"CalculateTFIDF\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a measure called \"text frequency / (inverse) document frequency\" that combines a *local* measure (how frequently a word appears in a segment, in comparison to the other words appearing in the same segment, viz. the table above), with a *global* measure (how frequently the word appears throughout the whole corpus). Roughly speaking, we have to add to the table above a new, global, element: the number of *documents* the term appears in divided through the number of *all documents* in the corpus - or, rather, the other way round (that's why it is the \"*inverse*\" document frequency): the number of documents in the corpus divided by the number of documents the current term occurs in. *(As with our local measure above, there is also some normalization, i.e. compensation for different lengths of documents and attenuation of high values, going on by using a logarithm on the quotient.)*\n",
    "\n",
    "When you multiply the term frequency (from above) with this inverse document frequeny, you have a formula which \"rewards\" frequent occurrences in one segment and rare occurrences over the whole corpus. (For more of the mathematical background, see [this tutorial](http://blog.christianperone.com/2011/10/machine-learning-text-feature-extraction-tf-idf-part-ii/).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we do not have to implement all the counting, division and logarithm ourselves but can rely on SciKit-learn's TfidfVectorizer function to generate a matrix of our corpus in just a few lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:49.055484Z",
     "start_time": "2017-11-10T11:14:49.009479Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1542</th>\n",
       "      <th>1549</th>\n",
       "      <th>1555</th>\n",
       "      <th>1563</th>\n",
       "      <th>1568</th>\n",
       "      <th>1581</th>\n",
       "      <th>1591</th>\n",
       "      <th>1595</th>\n",
       "      <th>1601</th>\n",
       "      <th>1604</th>\n",
       "      <th>...</th>\n",
       "      <th>voluntad</th>\n",
       "      <th>voluntarius</th>\n",
       "      <th>vos</th>\n",
       "      <th>vot</th>\n",
       "      <th>votum</th>\n",
       "      <th>vulgatus</th>\n",
       "      <th>vulgo</th>\n",
       "      <th>words1</th>\n",
       "      <th>zalsius</th>\n",
       "      <th>zassi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062335</td>\n",
       "      <td>0.062335</td>\n",
       "      <td>0.062335</td>\n",
       "      <td>0.062335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064922</td>\n",
       "      <td>0.073857</td>\n",
       "      <td>0.073857</td>\n",
       "      <td>0.073857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071201</td>\n",
       "      <td>0.081001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124432</td>\n",
       "      <td>0.124432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088002</td>\n",
       "      <td>0.088002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 1309 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1542      1549      1555      1563      1568      1581      1591  \\\n",
       "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4   0.062335  0.062335  0.062335  0.062335  0.000000  0.000000  0.000000   \n",
       "5   0.000000  0.000000  0.000000  0.000000  0.064922  0.073857  0.073857   \n",
       "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "8   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "10  0.000000  0.000000  0.000000  0.000000  0.064789  0.000000  0.000000   \n",
       "11  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "12  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "13  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "14  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "15  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "16  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "17  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "18  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "19  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        1595      1601      1604    ...     voluntad  voluntarius       vos  \\\n",
       "0   0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "1   0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "2   0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "3   0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "4   0.000000  0.000000  0.062335    ...     0.054794     0.000000  0.000000   \n",
       "5   0.073857  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "6   0.000000  0.064248  0.000000    ...     0.071201     0.081001  0.000000   \n",
       "7   0.000000  0.056385  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "8   0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "9   0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "10  0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "11  0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "12  0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "13  0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "14  0.000000  0.072300  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "15  0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "16  0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.088002   \n",
       "17  0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "18  0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "19  0.000000  0.000000  0.000000    ...     0.000000     0.000000  0.000000   \n",
       "\n",
       "         vot     votum  vulgatus     vulgo    words1   zalsius     zassi  \n",
       "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "5   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "6   0.000000  0.000000  0.000000  0.081001  0.000000  0.000000  0.000000  \n",
       "7   0.000000  0.071088  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "8   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.124432  0.124432  \n",
       "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "11  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "12  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "13  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "14  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "15  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "16  0.088002  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "17  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "18  0.000000  0.000000  0.134299  0.000000  0.000000  0.000000  0.000000  \n",
       "19  0.000000  0.000000  0.000000  0.000000  0.117808  0.000000  0.000000  \n",
       "\n",
       "[20 rows x 1309 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the library's function\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stopwords, use_idf=True, tokenizer=ourLemmatiser, norm='l2')\n",
    "\n",
    "# Finally, we feed our corpus to the function to build a new \"tfidf_matrix\" object\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Print some results\n",
    "tfidf_matrix_frame = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names())\n",
    "\n",
    "tfidf_matrix_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's print a more qualified \"top 10\" words for each segment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:49.474526Z",
     "start_time": "2017-11-10T11:14:49.381516Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Most significant words segment 0:\n",
      "          lemma  tf/idf value\n",
      "0      damnatio      0.331894\n",
      "1      iniustus      0.331894\n",
      "2         sisto      0.291740\n",
      "3        usurpo      0.291740\n",
      "4         origo      0.263250\n",
      "5         prior      0.263250\n",
      "6         caput      0.241152\n",
      "7       commune      0.241152\n",
      "8         color      0.241152\n",
      "9        indios      0.239917\n",
      "10    servitium      0.239917\n",
      "11     libertas      0.223096\n",
      "12        liber      0.207830\n",
      "13      persona      0.194606\n",
      "14   personalis      0.163069\n",
      "15       tribuo      0.154452\n",
      "16       perú_p      0.000000\n",
      "17         peto      0.000000\n",
      "18         1542      0.000000\n",
      "19  perversitas      0.000000\n",
      " \n",
      " Most significant words segment 1:\n",
      "        lemma  tf/idf value\n",
      "0         ius      0.340458\n",
      "1       liber      0.264301\n",
      "2       prior      0.200868\n",
      "3      repeto      0.148404\n",
      "4       bonus      0.133912\n",
      "5         iur      0.122671\n",
      "6      indios      0.122043\n",
      "7       debeo      0.105720\n",
      "8      refero      0.098994\n",
      "9     elegans      0.084415\n",
      "10      recto      0.084415\n",
      "11     qualis      0.084415\n",
      "12   quaestio      0.084415\n",
      "13    disputo      0.084415\n",
      "14  distribuo      0.084415\n",
      "15  diuturnus      0.084415\n",
      "16    prorsus      0.084415\n",
      "17       dono      0.084415\n",
      "18   earumque      0.084415\n",
      "19     procur      0.084415\n",
      " \n",
      " Most significant words segment 2:\n",
      "           lemma  tf/idf value\n",
      "0       utilitas      0.205950\n",
      "1          soleo      0.152248\n",
      "2       subdolus      0.129827\n",
      "3         deludo      0.129827\n",
      "4         excolo      0.129827\n",
      "5       aedifico      0.129827\n",
      "6          aetas      0.129827\n",
      "7       percipio      0.129827\n",
      "8          sexus      0.129827\n",
      "9         defero      0.129827\n",
      "10          ager      0.129827\n",
      "11        fodina      0.129827\n",
      "12         pasco      0.129827\n",
      "13      operaque      0.129827\n",
      "14       onustus      0.129827\n",
      "15     intelligo      0.129827\n",
      "16  contemplatio      0.129827\n",
      "17    contractus      0.129827\n",
      "18    contrarium      0.129827\n",
      "19       semotus      0.129827\n",
      " \n",
      " Most significant words segment 3:\n",
      "           lemma  tf/idf value\n",
      "0          pendo      0.237419\n",
      "1        praesto      0.188315\n",
      "2         plenus      0.188315\n",
      "3          iubeo      0.172507\n",
      "4         certus      0.172507\n",
      "5         indios      0.171623\n",
      "6         tribuo      0.165730\n",
      "7          lapis      0.118709\n",
      "8         quando      0.118709\n",
      "9        hispani      0.118709\n",
      "10       appareo      0.118709\n",
      "11       protego      0.118709\n",
      "12     commendam      0.118709\n",
      "13          vexo      0.118709\n",
      "14  praetermitto      0.118709\n",
      "15    famulitium      0.118709\n",
      "16         durus      0.118709\n",
      "17       instruo      0.118709\n",
      "18      detectio      0.118709\n",
      "19    quantumvis      0.118709\n",
      " \n",
      " Most significant words segment 4:\n",
      "         lemma  tf/idf value\n",
      "0   personalis      0.183763\n",
      "1         anno      0.181170\n",
      "2        eodem      0.164382\n",
      "3         semi      0.146202\n",
      "4           fr      0.124671\n",
      "5        decad      0.124671\n",
      "6     provisio      0.124671\n",
      "7        están      0.124671\n",
      "8    tractatus      0.124671\n",
      "9     permitto      0.124671\n",
      "10      memoro      0.124671\n",
      "11       dadas      0.124671\n",
      "12      indios      0.112652\n",
      "13   servitium      0.112652\n",
      "14        queo      0.110080\n",
      "15        voco      0.109588\n",
      "16        alea      0.104566\n",
      "17      regnum      0.098886\n",
      "18     expedio      0.098886\n",
      "19        ioan      0.090585\n",
      " \n",
      " Most significant words segment 5:\n",
      "             lemma  tf/idf value\n",
      "0           regnum      0.292909\n",
      "1             anno      0.214657\n",
      "2             alea      0.154867\n",
      "3           prorex      0.147715\n",
      "4         postmodo      0.147715\n",
      "5         quitensi      0.147715\n",
      "6         peruanum      0.147715\n",
      "7            nosco      0.129843\n",
      "8         servicio      0.117163\n",
      "9       personalis      0.108865\n",
      "10          certus      0.107328\n",
      "11         accipio      0.107328\n",
      "12             dom      0.107328\n",
      "13       servitium      0.080084\n",
      "14       monzonium      0.073857\n",
      "15         remaneo      0.073857\n",
      "16            está      0.073857\n",
      "17           modus      0.073857\n",
      "18           mitto      0.073857\n",
      "19  repartimientos      0.073857\n",
      " \n",
      " Most significant words segment 6:\n",
      "         lemma  tf/idf value\n",
      "0         semi      0.284969\n",
      "1         haya      0.284804\n",
      "2          por      0.176564\n",
      "3        casso      0.162002\n",
      "4        pario      0.162002\n",
      "5         volo      0.142402\n",
      "6         paro      0.142402\n",
      "7    servicios      0.128496\n",
      "8     servicio      0.128496\n",
      "9     personal      0.128496\n",
      "10      indios      0.117107\n",
      "11      tribuo      0.113085\n",
      "12         así      0.081001\n",
      "13  tolerandus      0.081001\n",
      "14    reparten      0.081001\n",
      "15    asservio      0.081001\n",
      "16     tierras      0.081001\n",
      "17     novembr      0.081001\n",
      "18     remedio      0.081001\n",
      "19      assero      0.081001\n",
      " \n",
      " Most significant words segment 7:\n",
      "           lemma  tf/idf value\n",
      "0         magnus      0.213264\n",
      "1          cuius      0.187462\n",
      "2       schedula      0.166730\n",
      "3           curo      0.154956\n",
      "4   montisclario      0.142176\n",
      "5        superus      0.142176\n",
      "6      marchioni      0.142176\n",
      "7      exsecutio      0.142176\n",
      "8   excellentiss      0.142176\n",
      "9         tracto      0.124975\n",
      "10         mereo      0.124975\n",
      "11      princeps      0.112770\n",
      "12        omnino      0.112770\n",
      "13          anno      0.103304\n",
      "14           dom      0.103304\n",
      "15          maga      0.103304\n",
      "16        indios      0.102775\n",
      "17          alea      0.089436\n",
      "18         annus      0.089030\n",
      "19         video      0.083365\n",
      " \n",
      " Most significant words segment 8:\n",
      "          lemma  tf/idf value\n",
      "0       liberta      0.339386\n",
      "1        centum      0.254540\n",
      "2         titio      0.223744\n",
      "3           hom      0.223744\n",
      "4          inst      0.201895\n",
      "5       de_stat      0.169693\n",
      "6        de_iur      0.169693\n",
      "7        person      0.169693\n",
      "8         liber      0.159391\n",
      "9         allec      0.134596\n",
      "10     servitus      0.134596\n",
      "11         maga      0.123298\n",
      "12        onero      0.123298\n",
      "13         queo      0.112375\n",
      "14          res      0.106261\n",
      "15    existimen      0.084847\n",
      "16          rer      0.084847\n",
      "17       corras      0.084847\n",
      "18    quis_fuer      0.084847\n",
      "19  et_demonstr      0.084847\n",
      " \n",
      " Most significant words segment 9:\n",
      "             lemma  tf/idf value\n",
      "0          de_oper      0.373295\n",
      "1         libertus      0.248863\n",
      "2               gl      0.218755\n",
      "3          praesto      0.197392\n",
      "4              ius      0.167284\n",
      "5            opera      0.129351\n",
      "6     debueruntque      0.124432\n",
      "7         de_usufr      0.124432\n",
      "8      de_acquisit      0.124432\n",
      "9         contendo      0.124432\n",
      "10            serv      0.124432\n",
      "11  si_ususfructus      0.124432\n",
      "12          ad_leg      0.124432\n",
      "13         vexatio      0.124432\n",
      "14          singul      0.124432\n",
      "15      supersedeo      0.124432\n",
      "16          servus      0.124432\n",
      "17       deminutio      0.124432\n",
      "18           zassi      0.124432\n",
      "19         propter      0.124432\n",
      " \n",
      " Most significant words segment 10:\n",
      "       lemma  tf/idf value\n",
      "0       auth      0.194368\n",
      "1     de_off      0.147413\n",
      "2      recop      0.147413\n",
      "3   illicito      0.147413\n",
      "4       sine      0.129578\n",
      "5      princ      0.129578\n",
      "6      pract      0.129578\n",
      "7      casus      0.129578\n",
      "8    violens      0.129578\n",
      "9       onus      0.129578\n",
      "10     novum      0.129578\n",
      "11       tot      0.116925\n",
      "12    impono      0.116925\n",
      "13       ibi      0.116925\n",
      "14      ioan      0.107109\n",
      "15     omnis      0.099090\n",
      "16     subdo      0.099090\n",
      "17      verb      0.099090\n",
      "18    noster      0.092309\n",
      "19    multus      0.092309\n",
      " \n",
      " Most significant words segment 11:\n",
      "         lemma  tf/idf value\n",
      "0           gl      0.227964\n",
      "1        opera      0.134797\n",
      "2        deleg      0.129670\n",
      "3         veto      0.129670\n",
      "4         eccl      0.129670\n",
      "5         iuro      0.129670\n",
      "6        navis      0.129670\n",
      "7          for      0.129670\n",
      "8   nuevamente      0.129670\n",
      "9        decim      0.129670\n",
      "10        prax      0.129670\n",
      "11      et_hon      0.129670\n",
      "12    sequitut      0.129670\n",
      "13      honoro      0.129670\n",
      "14       tusch      0.129670\n",
      "15        aloe      0.129670\n",
      "16         tut      0.129670\n",
      "17    et_curat      0.129670\n",
      "18      platea      0.129670\n",
      "19      multum      0.129670\n",
      " \n",
      " Most significant words segment 12:\n",
      "            lemma  tf/idf value\n",
      "0            marc      0.159257\n",
      "1       et_censit      0.159257\n",
      "2           angel      0.159257\n",
      "3        rosental      0.159257\n",
      "4   adscriptitiis      0.159257\n",
      "5        terminus      0.159257\n",
      "6         termino      0.159257\n",
      "7           propr      0.159257\n",
      "8         de_feud      0.159257\n",
      "9           husan      0.159257\n",
      "10            obs      0.159257\n",
      "11     de_hominib      0.159257\n",
      "12       de_offic      0.159257\n",
      "13      uvaremund      0.159257\n",
      "14       conservo      0.159257\n",
      "15         menoch      0.159257\n",
      "16            opt      0.159257\n",
      "17      pristinus      0.159257\n",
      "18          agric      0.159257\n",
      "19        verosim      0.159257\n",
      " \n",
      " Most significant words segment 13:\n",
      "            lemma  tf/idf value\n",
      "0             ult      0.213108\n",
      "1           trado      0.180602\n",
      "2            alea      0.169012\n",
      "3          refero      0.157539\n",
      "4         salicet      0.134338\n",
      "5          floreo      0.134338\n",
      "6         subiici      0.134338\n",
      "7     nova_vectig      0.134338\n",
      "8          utique      0.134338\n",
      "9            card      0.134338\n",
      "10         eisque      0.134338\n",
      "11          praet      0.134338\n",
      "12  si_publicanus      0.134338\n",
      "13         schard      0.134338\n",
      "14         aviles      0.134338\n",
      "15          vinea      0.134338\n",
      "16         albano      0.134338\n",
      "17       non_poss      0.134338\n",
      "18       salarium      0.134338\n",
      "19     restitutio      0.134338\n",
      " \n",
      " Most significant words segment 14:\n",
      "           lemma  tf/idf value\n",
      "0           dico      0.331153\n",
      "1            met      0.182305\n",
      "2          annus      0.171237\n",
      "3            iud      0.160249\n",
      "4   praescriptio      0.160249\n",
      "5           loca      0.160249\n",
      "6          facio      0.150731\n",
      "7           fero      0.144600\n",
      "8            res      0.114158\n",
      "9          video      0.106894\n",
      "10         soleo      0.106894\n",
      "11     servitium      0.098837\n",
      "12         fraus      0.091152\n",
      "13       defendo      0.091152\n",
      "14         sumta      0.091152\n",
      "15       citatus      0.091152\n",
      "16        mentio      0.091152\n",
      "17     plerumque      0.091152\n",
      "18        iurium      0.091152\n",
      "19     de_probat      0.091152\n",
      " \n",
      " Most significant words segment 15:\n",
      "            lemma  tf/idf value\n",
      "0           fides      0.386697\n",
      "1       possessor      0.329940\n",
      "2             lex      0.257948\n",
      "3            mala      0.219960\n",
      "4           dubio      0.219960\n",
      "5           bonum      0.174467\n",
      "6          contra      0.147855\n",
      "7          iudico      0.109980\n",
      "8   manumisiionib      0.109980\n",
      "9         affligo      0.109980\n",
      "10          alban      0.109980\n",
      "11         alieno      0.109980\n",
      "12           uxor      0.109980\n",
      "13      interdico      0.109980\n",
      "14    inter_pares      0.109980\n",
      "15       usucapio      0.109980\n",
      "16         usucap      0.109980\n",
      "17         ambigo      0.109980\n",
      "18         mercor      0.109980\n",
      "19         de_reg      0.109980\n",
      " \n",
      " Most significant words segment 16:\n",
      "         lemma  tf/idf value\n",
      "0         mali      0.176003\n",
      "1    emendatio      0.176003\n",
      "2         deus      0.176003\n",
      "3      corrigo      0.176003\n",
      "4        actio      0.154709\n",
      "5    violentia      0.154709\n",
      "6        bonus      0.139601\n",
      "7         ioan      0.127882\n",
      "8   iniustitia      0.088002\n",
      "9       expens      0.088002\n",
      "10       timor      0.088002\n",
      "11      testor      0.088002\n",
      "12      postul      0.088002\n",
      "13   indebitus      0.088002\n",
      "14   indagatio      0.088002\n",
      "15        cado      0.088002\n",
      "16  innocentio      0.088002\n",
      "17       audio      0.088002\n",
      "18     exerceo      0.088002\n",
      "19     exemplo      0.088002\n",
      " \n",
      " Most significant words segment 17:\n",
      "         lemma  tf/idf value\n",
      "0         dies      0.221947\n",
      "1       genero      0.221947\n",
      "2        solvo      0.183461\n",
      "3         dico      0.183461\n",
      "4       tribuo      0.176254\n",
      "5        opera      0.131239\n",
      "6   practicari      0.126248\n",
      "7      matienz      0.126248\n",
      "8        veneo      0.126248\n",
      "9      aestimo      0.126248\n",
      "10    cognitus      0.126248\n",
      "11      opinio      0.126248\n",
      "12         rus      0.126248\n",
      "13        regn      0.126248\n",
      "14      postea      0.126248\n",
      "15     inficio      0.126248\n",
      "16        hora      0.126248\n",
      "17  reiicienda      0.126248\n",
      "18     congero      0.126248\n",
      "19      perú_p      0.126248\n",
      " \n",
      " Most significant words segment 18:\n",
      "           lemma  tf/idf value\n",
      "0        de_pact      0.236102\n",
      "1         multus      0.168195\n",
      "2         indios      0.145622\n",
      "3      conveneri      0.134299\n",
      "4         alphan      0.134299\n",
      "5         turpis      0.134299\n",
      "6          valde      0.134299\n",
      "7       superbia      0.134299\n",
      "8   imbecillitas      0.134299\n",
      "9      republica      0.134299\n",
      "10         cuiac      0.134299\n",
      "11          dego      0.134299\n",
      "12       reporto      0.134299\n",
      "13       demoveo      0.134299\n",
      "14         quasi      0.134299\n",
      "15         semel      0.134299\n",
      "16      delictum      0.134299\n",
      "17       collect      0.134299\n",
      "18    granatensi      0.134299\n",
      "19         dotal      0.134299\n",
      " \n",
      " Most significant words segment 19:\n",
      "           lemma  tf/idf value\n",
      "0    perversitas      0.235615\n",
      "1         facile      0.235615\n",
      "2         servio      0.207109\n",
      "3        quamvis      0.207109\n",
      "4          sibus      0.129872\n",
      "5          sudor      0.117808\n",
      "6        itemque      0.117808\n",
      "7        perquam      0.117808\n",
      "8     summarium3      0.117808\n",
      "9          desum      0.117808\n",
      "10        aequum      0.117808\n",
      "11     constituo      0.117808\n",
      "12       detraho      0.117808\n",
      "13          fors      0.117808\n",
      "14      perficio      0.117808\n",
      "15  inaequabilis      0.117808\n",
      "16      rebusque      0.117808\n",
      "17      converto      0.117808\n",
      "18      vicesque      0.117808\n",
      "19       chapter      0.117808\n"
     ]
    }
   ],
   "source": [
    "# convert your matrix to an array to loop over it\n",
    "mx_array = tfidf_matrix.toarray()\n",
    "\n",
    "# get your feature names\n",
    "fn = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "pos = 0\n",
    "for l in mx_array:\n",
    "    print(' ')\n",
    "    print(' Most significant words segment ' + str(pos) + ':')\n",
    "    print(pd.DataFrame.rename(pd.DataFrame.from_dict([(fn[x], l[x]) for x in (l*-1).argsort()][:20]), columns={0:'lemma',1:'tf/idf value'}))\n",
    "    pos += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alertbox alert-success\">You can see that, in the fourth segment, pensum and tributum have moved up while indis has fallen from the first to the third place. But in other segments you can also see that abbreviations like \"fol\", \"gl\" or \"hom\" still are a major nuisance, and so are spanish passages. It would surely help to improve our stopwords and lemma lists.</div>\n",
    "\n",
    "<div class=\"alert alertbox alert-success\">Of course, having more text would also help: The *idf* can kick in only when there are many documents... Also, you could play around with the segmentation. Make fewer but bigger segments or smaller ones...</div>\n",
    "\n",
    "<div class=\"alert alertbox alert-success\">And you can notice that in many segments, the lemmata at around rank 5 have the exact same value. Most certainly that's because they only occur one single time in the segment. (That those values differ from segment to segment has to do with the relation of the segment to the corpus as a whole.) And when four our fourteen of those words occur only once anyway, we should really not think that there is a meaningful sorting order between them (or that there is a good reason the 8th one is in the top ten list and the thirteenth one isn't). But in those areas where there _is_ variation in the tf/idf values, that is indeed telling.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the way that they have been encoded in our sample texts, we can also observe some references to other literature by the underscore (e.g. \"de_oper\", \"de_iur\", \"et_cur\" etc.), which makes you wonder if it would be worthwile marking all the references in some way so that we could either concentrate on them or filter them out altogether. But other than that, it's in fact almost meaningful. Apart from making such lists, what can we do with this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Space Model of the text <a name=\"#VectorSpaceModel\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us recapitulate in more general terms what we have done so far, since a good part of it is extensible and applicable to many other methods: We have used a representation of each \"document\" (in our case, all those \"documents\" have been segments of one and the same text) as a series of values that indicated the document's relevance in particular \"dimensions\".\n",
    "\n",
    "For example, the various values in the \"alea dimension\" indicate how characteristic this word, \"alea\", is for the present document. (By hypothesis, this also works the other way round, as an indication of which documents are the most relevant ones in matters of \"alea\". In fact, this is how search engines work.)\n",
    "\n",
    "Many words did not occur at all in most of the documents and the series of values (matrix rows) contained many zeroes. Other words were stopwords which we would not want to affect our documents' scores - they did not yield a salient \"dimension\" and were dropped from the series of values (matrix columns). The values work independently and can be combined (when a document is relevant in one *and* in another dimension).\n",
    "\n",
    "Each document is thus characterised by a so-called \"vector\" (a series of independent, combinable values) and is mapped in a \"space\" constituted by the dimensions of those vectors (matrix columns, series of values). In our case the dimensions have been derived from the corpus's vocabulary. Hence, the representation of all the documents is called their vector space model. You can really think of it as similar to a three-dimensional space: *Document A goes quite some way in the x-direction, it goes not at all in the y-direction and it goes just a little bit in the z-direction. Document B goes quite some way, perhaps even further than A did, in both the y- and z- directions, but only a wee bit in the y-direction. Etc. etc. Only with many many more independent dimensions instead of just the three spatial dimensions we are used to.*\n",
    "\n",
    "The following sections are will discuss ways of manipulating the vector space -- using alternative or additional dimensions -- and also ways of leveraging the VSM representation of our text to make various analyses..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1. [Alternative vector space constitution: n-grams](#N-Grams)\n",
    "  2. [Extending the space's dimensions](#AddDimensions)\n",
    "  3. [Word clouds](#WordClouds)\n",
    "  4. [Similarity](#DocumentSimilarity)\n",
    "  5. [Clustering](#DocumentClustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another method to generate the dimensions: n-grams <a name=\"N-Grams\"/>\n",
    "\n",
    "Instead of relying on the (either lemmatized or un-lemmatized) vocabulary of words occurring in your documents, you could also use other methods to generate a vector for them. A very popular such method is called n-grams and shall be presented just shortly:\n",
    "\n",
    "Imagine a moving window which captures, say, three words and slides over your text word by word. The first capture would get the first three words, the second one the words two to four, the third one the words three to five, and so on up to the last three words of your document. This procedure would generate all the \"3-grams\" contained in your text - not all the possible combinations of the words present in the vocabulary but just the triples that happen to occur in the text. The meaningfulness of this method depends to a certain extent on how strongly the respective language inflects its words and on how freely it orders its sentences' parts (a sociolect or literary genre might constrain or enhance the potential variance of the language). Less variance here means that the same ideas tend to be (!) presented in the same formulations more than in languages with more variance on this syntactic level. To a certain extent, you could play around with lemmatization and stopwords and with the size of your window. But in general, there are more 3-grams repeated in human language than one would expect. Even more so if we imagine our window encompassing only two words, resulting in 2-grams or, rather, bigrams.\n",
    "\n",
    "As a quick example, let's list the top bi- or 3-grams of our text segments, together with the respective number of occurrences, and the 10 most frequent n-grams in the whole corpus:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:51.569735Z",
     "start_time": "2017-11-10T11:14:51.268705Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent 2-/3-grams\n",
      "========================\n",
      " \n",
      "Segment 0:\n",
      "  This segment has no bi- or 3-gram occurring more than just once.\n",
      " \n",
      "Segment 1:\n",
      "      n-gram  count\n",
      "1852    d de      3\n",
      "3721  in lib      2\n",
      "7053  sum et      2\n",
      "4278     l 2      2\n",
      "6157  qui in      2\n",
      " \n",
      "Segment 2:\n",
      "  This segment has no bi- or 3-gram occurring more than just once.\n",
      " \n",
      "Segment 3:\n",
      "                    n-gram  count\n",
      "5754         praesto iubeo      2\n",
      "845           ago eiusmodi      1\n",
      "3653          in commendam      1\n",
      "3654  in commendam accipio      1\n",
      "846   ago eiusmodi hispani      1\n",
      " \n",
      "Segment 4:\n",
      "                        n-gram  count\n",
      "6735      servitium personalis      4\n",
      "2908                   et seqq      4\n",
      "6660                   seqq et      3\n",
      "3416  hic servitium personalis      3\n",
      "3414             hic servitium      3\n",
      " \n",
      "Segment 5:\n",
      "            n-gram  count\n",
      "2615       et alea      3\n",
      "2747         et in      2\n",
      "5065  nosco regnum      2\n",
      "2313         dom d      2\n",
      "7428   tribuo taxa      1\n",
      " \n",
      "Segment 6:\n",
      "                 n-gram  count\n",
      "6044            que los      2\n",
      "4586         los indios      2\n",
      "2527             eo que      2\n",
      "4556             lo que      2\n",
      "6687  servicio personal      2\n",
      " \n",
      "Segment 7:\n",
      "                      n-gram  count\n",
      "2747                   et in      3\n",
      "1825       curo excellentiss      2\n",
      "7760               video sum      2\n",
      "4685  marchioni montisclario      2\n",
      "3112          exsecutio curo      1\n",
      " \n",
      "Segment 8:\n",
      "            n-gram  count\n",
      "4278           l 2      3\n",
      "7317  titio centum      3\n",
      "235            2 d      3\n",
      "4267           l 1      2\n",
      "1759      cum alea      2\n",
      " \n",
      "Segment 9:\n",
      "         n-gram  count\n",
      "3709       in l      3\n",
      "3711     in l 2      2\n",
      "4427      lib 1      2\n",
      "4278        l 2      2\n",
      "1876  d de_oper      2\n",
      " \n",
      "Segment 10:\n",
      "          n-gram  count\n",
      "7           1 et      3\n",
      "1287        c ne      3\n",
      "4297  l illicito      2\n",
      "446         4 ne      2\n",
      "2959  et violens      2\n",
      " \n",
      "Segment 11:\n",
      "     n-gram  count\n",
      "3709   in l      3\n",
      "0       1 c      2\n",
      "4267    l 1      2\n",
      "5293    p 5      2\n",
      "4268  l 1 c      2\n",
      " \n",
      "Segment 12:\n",
      "  This segment has no bi- or 3-gram occurring more than just once.\n",
      " \n",
      "Segment 13:\n",
      "                 n-gram  count\n",
      "4335              l ult      2\n",
      "2615            et alea      2\n",
      "6366     refero salicet      1\n",
      "7624  utique vel rapiña      1\n",
      "1852               d de      1\n",
      " \n",
      "Segment 14:\n",
      "           n-gram  count\n",
      "1852         d de      2\n",
      "5027  nolo possum      2\n",
      "4870         ne 2      2\n",
      "446          4 ne      2\n",
      "4314         l si      2\n",
      " \n",
      "Segment 15:\n",
      "           n-gram  count\n",
      "1852         d de      3\n",
      "7476      ubi lex      2\n",
      "6067  queo contra      2\n",
      "1211  bonum fides      2\n",
      "4646   mala fides      2\n",
      " \n",
      "Segment 16:\n",
      "           n-gram  count\n",
      "2735       et hic      2\n",
      "4443        lib 2      2\n",
      "4851         ne 1      2\n",
      "3637         in c      2\n",
      "1670  contra deus      1\n",
      " \n",
      "Segment 17:\n",
      "            n-gram  count\n",
      "7405     tribuo in      2\n",
      "3790        in qui      2\n",
      "0              1 c      1\n",
      "1650     consto ut      1\n",
      "4477  lib conficio      1\n",
      " \n",
      "Segment 18:\n",
      "                n-gram  count\n",
      "1879         d de_pact      2\n",
      "2839       et paciscor      1\n",
      "3536  ille et paciscor      1\n",
      "7379           trado a      1\n",
      "6615       semel sibus      1\n",
      " \n",
      "Segment 19:\n",
      "  This segment has no bi- or 3-gram occurring more than just once.\n",
      " \n",
      " \n",
      "The 10 most frequent n-grams in the whole corpus\n",
      "================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>in l</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et in</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lib 2</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d de</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>servitium personalis</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l 1</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et alea</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et seqq</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l 2</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in qui</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count\n",
       "in l                     14\n",
       "et in                    13\n",
       "lib 2                    12\n",
       "d de                     10\n",
       "servitium personalis     10\n",
       "l 1                       9\n",
       "et alea                   8\n",
       "et seqq                   8\n",
       "l 2                       7\n",
       "in qui                    6"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_size_high = 3\n",
    "ngram_size_low  = 2\n",
    "top_n = 5\n",
    "\n",
    "# Initialize the TfidfVectorizer function from above\n",
    "# (again using our lemmatising fct. but no stopwords this time)\n",
    "vectorizer = CountVectorizer(ngram_range=(ngram_size_low, ngram_size_high), tokenizer=ourLemmatiser)\n",
    "ngrams = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print('Most frequent 2-/3-grams')\n",
    "print('========================')\n",
    "print(' ')\n",
    "ngrams_dict = []\n",
    "df = []\n",
    "df_2 = []\n",
    "for i in range(0, len(corpus)):\n",
    "    # (probably that's way too complicated here...)\n",
    "    ngrams_dict.append(dict(zip(vectorizer.get_feature_names(), ngrams.toarray()[i])))\n",
    "    df.append(pd.DataFrame.from_dict(ngrams_dict[i], orient='index').reset_index())\n",
    "    df_2.append(df[i].rename(columns={'index':'n-gram',0:'count'}))\n",
    "    print('Segment ' + str(i) + ':')\n",
    "    if df_2[i]['count'].max() > 1:\n",
    "        print(df_2[i].sort_values(by='count',axis=0,ascending=False)[:top_n])\n",
    "        print(' ')\n",
    "    else:\n",
    "        print('  This segment has no bi- or 3-gram occurring more than just once.')\n",
    "        print(' ')\n",
    "\n",
    "ngrams_corpus = pd.DataFrame(ngrams.todense(), columns=vectorizer.get_feature_names())\n",
    "ngrams_total = ngrams_corpus.cumsum()\n",
    "print(' ')\n",
    "print(\"The 10 most frequent n-grams in the whole corpus\")\n",
    "print(\"================================================\")\n",
    "ngrams_total.tail(1).T.rename(columns={19:'count'}).nlargest(10, 'count')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending the dimensions <a name=\"AddDimensions\"/>\n",
    "\n",
    "Of course, there is no reason why the dimensions should be restricted to or identical with the vocabulary (or the occurring n-grams, for that matter). In fact, in the examples above, we have dropped some of the words already by using our list of stopwords. <font color=\"green\">**We could also add other dimensions that are of interest for our current research question. We could add a dimension for the year in which the texts have been written, for their citing a certain author, or merely for their position in the encompassing work...**</font>\n",
    "\n",
    "Since in our examples, the position is represented in the \"row number\" and counting citations of a particular author require some more normalisations (e.g. with the lemmatisation dictionary above), let's add a dimension for the length of the respective segment (in characters) and another one for the number of occurrences of \"\\_\" (in our sample transcriptions, this character had been used to mark citations, although admittedly not all of them), just so you get the idea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:51.586737Z",
     "start_time": "2017-11-10T11:14:51.572735Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original matrix of tf/idf values (rightmost columns):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vulgatus</th>\n",
       "      <th>vulgo</th>\n",
       "      <th>words1</th>\n",
       "      <th>zalsius</th>\n",
       "      <th>zassi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124432</td>\n",
       "      <td>0.124432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.134299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    vulgatus     vulgo    words1   zalsius     zassi\n",
       "0   0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "1   0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "2   0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "3   0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "4   0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "5   0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "6   0.000000  0.081001  0.000000  0.000000  0.000000\n",
       "7   0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "8   0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "9   0.000000  0.000000  0.000000  0.124432  0.124432\n",
       "10  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "11  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "12  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "13  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "14  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "15  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "16  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "17  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "18  0.134299  0.000000  0.000000  0.000000  0.000000\n",
       "19  0.000000  0.000000  0.117808  0.000000  0.000000"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Original matrix of tf/idf values (rightmost columns):\")\n",
    "tfidf_matrix_frame.iloc[ :, -5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:51.686747Z",
     "start_time": "2017-11-10T11:14:51.587737Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New matrix extended with segment length and number of occurrences of '_':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vulgo</th>\n",
       "      <th>words1</th>\n",
       "      <th>zalsius</th>\n",
       "      <th>zassi</th>\n",
       "      <th>seg_length</th>\n",
       "      <th>cit_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>313</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.081001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>254</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124432</td>\n",
       "      <td>0.124432</td>\n",
       "      <td>144</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>396</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>138</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>122</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>294</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>139</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>144</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>127</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       vulgo    words1   zalsius     zassi  seg_length  cit_count\n",
       "0   0.000000  0.000000  0.000000  0.000000          34          0\n",
       "1   0.000000  0.000000  0.000000  0.000000         268          0\n",
       "2   0.000000  0.000000  0.000000  0.000000         119          0\n",
       "3   0.000000  0.000000  0.000000  0.000000         140          0\n",
       "4   0.000000  0.000000  0.000000  0.000000         510          0\n",
       "5   0.000000  0.000000  0.000000  0.000000         313          0\n",
       "6   0.081001  0.000000  0.000000  0.000000         246          0\n",
       "7   0.000000  0.000000  0.000000  0.000000         304          0\n",
       "8   0.000000  0.000000  0.000000  0.000000         254         15\n",
       "9   0.000000  0.000000  0.124432  0.124432         144          9\n",
       "10  0.000000  0.000000  0.000000  0.000000         396          7\n",
       "11  0.000000  0.000000  0.000000  0.000000         138          7\n",
       "12  0.000000  0.000000  0.000000  0.000000         122          4\n",
       "13  0.000000  0.000000  0.000000  0.000000         113          3\n",
       "14  0.000000  0.000000  0.000000  0.000000         294          8\n",
       "15  0.000000  0.000000  0.000000  0.000000         139          7\n",
       "16  0.000000  0.000000  0.000000  0.000000         253          0\n",
       "17  0.000000  0.000000  0.000000  0.000000         144          4\n",
       "18  0.000000  0.000000  0.000000  0.000000         127          3\n",
       "19  0.000000  0.117808  0.000000  0.000000         150          0"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = []\n",
    "for i in range(0, len(corpus)):\n",
    "    length.append(len(tokenised[i]))\n",
    "\n",
    "citnum = []\n",
    "for i in range(0, len(corpus)):\n",
    "    citnum.append(corpus[i].count('_'))\n",
    "\n",
    "print(\"New matrix extended with segment length and number of occurrences of '_':\")\n",
    "new_matrix = tfidf_matrix_frame.assign(seg_length = length).assign(cit_count = citnum)\n",
    "new_matrix.iloc[ :, -6:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that the segment with most occurrences of \"\\_\" (taken with a grain of salt, that's likely the segment with most citations), is not a particularly long one. If we had systematic markup of citations or author names in our transcription, we could be more certain or add even more columns/\"dimensions\" to our table.\n",
    "\n",
    "If you bear with me for a final example, here is adding the labels that you could see in our initial one \"big source file\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:51.903769Z",
     "start_time": "2017-11-10T11:14:51.883767Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 labels read.\n",
      "New matrix extended with segment length, number of occurrences of '_' and label:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words1</th>\n",
       "      <th>zalsius</th>\n",
       "      <th>zassi</th>\n",
       "      <th>seg_length</th>\n",
       "      <th>cit_count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>[Book title]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>268</td>\n",
       "      <td>0</td>\n",
       "      <td>[Indians are free]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>[Definition of «servicios personales»]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>[rights &amp; duties of both Indians &amp; Spaniards]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "      <td>[literature &amp; royal decrees against the servic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>313</td>\n",
       "      <td>0</td>\n",
       "      <td>[Practical case from Peru – Viceroy Toledo in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "      <td>[Decree of the servicio personal, 1601]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "      <td>[implementation of the decree of the servicio ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>254</td>\n",
       "      <td>15</td>\n",
       "      <td>[definition of freedom ex Aristotle]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124432</td>\n",
       "      <td>0.124432</td>\n",
       "      <td>144</td>\n",
       "      <td>9</td>\n",
       "      <td>[encomiendas in theory]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>396</td>\n",
       "      <td>7</td>\n",
       "      <td>[Spaniards’ illegal imposition of labour over ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>138</td>\n",
       "      <td>7</td>\n",
       "      <td>[on vassals]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>122</td>\n",
       "      <td>4</td>\n",
       "      <td>[on colons &amp; adscripticios]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>[on both – vassals &amp; colons]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>294</td>\n",
       "      <td>8</td>\n",
       "      <td>[on time passing &amp; habits]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>139</td>\n",
       "      <td>7</td>\n",
       "      <td>[on usucapione, which does not apply in the ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>[habits established over time are not excuse f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>144</td>\n",
       "      <td>4</td>\n",
       "      <td>[Practical case from Peru – with literature]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>127</td>\n",
       "      <td>3</td>\n",
       "      <td>[work extorted in axchange for tribute]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.117808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>[corruption of the practice – turned into habi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      words1   zalsius     zassi  seg_length  cit_count  \\\n",
       "0   0.000000  0.000000  0.000000          34          0   \n",
       "1   0.000000  0.000000  0.000000         268          0   \n",
       "2   0.000000  0.000000  0.000000         119          0   \n",
       "3   0.000000  0.000000  0.000000         140          0   \n",
       "4   0.000000  0.000000  0.000000         510          0   \n",
       "5   0.000000  0.000000  0.000000         313          0   \n",
       "6   0.000000  0.000000  0.000000         246          0   \n",
       "7   0.000000  0.000000  0.000000         304          0   \n",
       "8   0.000000  0.000000  0.000000         254         15   \n",
       "9   0.000000  0.124432  0.124432         144          9   \n",
       "10  0.000000  0.000000  0.000000         396          7   \n",
       "11  0.000000  0.000000  0.000000         138          7   \n",
       "12  0.000000  0.000000  0.000000         122          4   \n",
       "13  0.000000  0.000000  0.000000         113          3   \n",
       "14  0.000000  0.000000  0.000000         294          8   \n",
       "15  0.000000  0.000000  0.000000         139          7   \n",
       "16  0.000000  0.000000  0.000000         253          0   \n",
       "17  0.000000  0.000000  0.000000         144          4   \n",
       "18  0.000000  0.000000  0.000000         127          3   \n",
       "19  0.117808  0.000000  0.000000         150          0   \n",
       "\n",
       "                                                label  \n",
       "0                                        [Book title]  \n",
       "1                                  [Indians are free]  \n",
       "2              [Definition of «servicios personales»]  \n",
       "3       [rights & duties of both Indians & Spaniards]  \n",
       "4   [literature & royal decrees against the servic...  \n",
       "5   [Practical case from Peru – Viceroy Toledo in ...  \n",
       "6             [Decree of the servicio personal, 1601]  \n",
       "7   [implementation of the decree of the servicio ...  \n",
       "8                [definition of freedom ex Aristotle]  \n",
       "9                             [encomiendas in theory]  \n",
       "10  [Spaniards’ illegal imposition of labour over ...  \n",
       "11                                       [on vassals]  \n",
       "12                        [on colons & adscripticios]  \n",
       "13                       [on both – vassals & colons]  \n",
       "14                         [on time passing & habits]  \n",
       "15  [on usucapione, which does not apply in the ca...  \n",
       "16  [habits established over time are not excuse f...  \n",
       "17       [Practical case from Peru – with literature]  \n",
       "18            [work extorted in axchange for tribute]  \n",
       "19  [corruption of the practice – turned into habi...  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input should still have a handle on our source file.\n",
    "\n",
    "label = []\n",
    "# Now, for every line, revisit the special string and extract just the lines marked by it\n",
    "for line in input:\n",
    "    if line[0:3] == '€€€':\n",
    "        label.append(line[6:].strip())\n",
    "\n",
    "# How many segments/files do we then have?\n",
    "print(str(len(label)) + ' labels read.')\n",
    "print(\"New matrix extended with segment length, number of occurrences of '_' and label:\")\n",
    "yet_another_matrix = new_matrix.assign(seg_length = length).assign(label = label)\n",
    "yet_another_matrix.iloc[ :, -6:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Clouds <a name=\"WordClouds\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a library that takes word frequencies like above, calculates corresponding relative sizes of words and creates nice wordcloud images for our sections (again, taking the fourth segment as an example) like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:52.751853Z",
     "start_time": "2017-11-10T11:14:52.486827Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAADKCAYAAABDsfw/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3611fa70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We make tuples of (lemma, tf/idf score) for one of our segments\n",
    "# But we have to convert our tf/idf weights to pseudo-frequencies (i.e. integer numbers)\n",
    "frq = [ int(round(x * 100000, 0)) for x in mx_array[3]]\n",
    "freq = dict(zip(fn, frq))\n",
    "\n",
    "wc = WordCloud(background_color=None, mode=\"RGBA\", max_font_size=40, relative_scaling=1).fit_words(freq)\n",
    "\n",
    "# Now show/plot the wordcloud\n",
    "plt.figure()\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have a nicer overview over the many segments than is possible in this notebook, let's create a new html file listing some of the characteristics that we have found so far..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:55.100088Z",
     "start_time": "2017-11-10T11:14:52.824861Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputDir = \"Solorzano\"\n",
    "htmlfile = open(outputDir + '/Overview.html', encoding='utf-8', mode='w')\n",
    "\n",
    "# Write the html header and the opening of a layout table\n",
    "htmlfile.write(\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "    <head>\n",
    "        <title>Section Characteristics</title>\n",
    "        <meta charset=\"utf-8\"/>\n",
    "    </head>\n",
    "    <body>\n",
    "        <table>\n",
    "\"\"\")\n",
    "\n",
    "a = [[]]\n",
    "a.clear()\n",
    "dicts = []\n",
    "w = []\n",
    "\n",
    "# For each segment, create a wordcloud and write it along with label and\n",
    "# other information into a new row of the html table\n",
    "for i in range(0, len(mx_array)):\n",
    "    # this is like above in the single-segment example...\n",
    "    a.append([ int(round(x * 100000, 0)) for x in mx_array[i]])\n",
    "    dicts.append(dict(zip(fn, a[i])))\n",
    "    w.append(WordCloud(background_color=None, mode=\"RGBA\", \\\n",
    "                       max_font_size=40, min_font_size=10, \\\n",
    "                       max_words=60, relative_scaling=0.8).fit_words(dicts[i]))\n",
    "    # We write the wordcloud image to a file\n",
    "    w[i].to_file(outputDir + '/wc_' + str(i) + '.png')\n",
    "    # Finally we write the column row\n",
    "    htmlfile.write(\"\"\"\n",
    "            <tr>\n",
    "                <td>\n",
    "                    <head>Section {a}: <b>{b}</b></head><br/>\n",
    "                    <img src=\"./wc_{a}.png\"/><br/>\n",
    "                    <small><i>length: {c} words</i></small>\n",
    "                </td>\n",
    "            </tr>\n",
    "            <tr><td>&nbsp;</td></tr>\n",
    "\"\"\".format(a = str(i), b = label[i], c = len(tokenised[i])))\n",
    "\n",
    "# And then we write the end of the html file.\n",
    "htmlfile.write(\"\"\"\n",
    "        </table>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\")\n",
    "htmlfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should have created a nice html file which we can open [here](./Solorzano/Overview.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T07:42:37.598721Z",
     "start_time": "2017-07-11T09:42:37.587926+02:00"
    }
   },
   "source": [
    "## Similarity <a name=\"DocumentSimilarity\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, once we have a representation of our text as a vector - which we can imagine as an arrow that goes a certain distance in one direction, another distance in another direction and so on - we can compare the different arrows. Do they go the same distance in a particular direction? And maybe almost the same in another direction? This would mean that one of the terms of our vocabulary has the same weight in both texts. Comparing the weight of our many, many dimensions, we can develop a measure for the similarity of the texts.\n",
    "\n",
    "(Probably, similarity in words that are occurring all over the place in the corpus should not count so much, and in fact it is attenuated by our arrows being made up of tf/idf weights.)\n",
    "\n",
    "Comparing arrows means calculating with angles and technically, what we are computing is the \"cosine similarity\" of texts. Again, there is a library ready for us to use (but you can find some documentation [here](http://blog.christianperone.com/2013/09/machine-learning-cosine-similarity-for-vector-space-models-part-iii/), [here](http://scikit-learn.org/stable/modules/metrics.html#cosine-similarity) and [here](https://en.wikipedia.org/wiki/Cosine_similarity).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:55.123090Z",
     "start_time": "2017-11-10T11:14:55.101088Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise similarities:\n",
      "          0         1         2         3         4         5         6   \\\n",
      "0   0.000000  0.222897  0.120293  0.147745  0.130148  0.081761  0.094125   \n",
      "1   0.222897  0.000000  0.092630  0.072586  0.082198  0.029001  0.030976   \n",
      "2   0.120293  0.092630  0.000000  0.057610  0.120441  0.043699  0.041051   \n",
      "3   0.147745  0.072586  0.057610  0.000000  0.131746  0.097417  0.056908   \n",
      "4   0.130148  0.082198  0.120441  0.131746  0.000000  0.221282  0.181299   \n",
      "5   0.081761  0.029001  0.043699  0.097417  0.221282  0.000000  0.141404   \n",
      "6   0.094125  0.030976  0.041051  0.056908  0.181299  0.141404  0.000000   \n",
      "7   0.035931  0.067855  0.035364  0.082660  0.132764  0.162764  0.081296   \n",
      "8   0.100506  0.166803  0.060454  0.083347  0.078576  0.039125  0.044615   \n",
      "9   0.044722  0.086246  0.019550  0.102677  0.076310  0.039573  0.020726   \n",
      "10  0.025080  0.067164  0.076931  0.052992  0.110786  0.050311  0.022992   \n",
      "11  0.000000  0.005779  0.000000  0.026106  0.041592  0.008422  0.010421   \n",
      "12  0.027620  0.055453  0.014834  0.011949  0.044076  0.027170  0.005829   \n",
      "13  0.011649  0.043319  0.030025  0.020825  0.056447  0.062899  0.000000   \n",
      "14  0.054892  0.066205  0.060191  0.082729  0.118508  0.078591  0.037649   \n",
      "15  0.044378  0.036802  0.039557  0.070395  0.056771  0.038931  0.012981   \n",
      "16  0.021745  0.090299  0.014982  0.040984  0.067496  0.038400  0.019335   \n",
      "17  0.070181  0.080908  0.079733  0.139602  0.119730  0.087217  0.079050   \n",
      "18  0.068122  0.050428  0.062793  0.058399  0.112498  0.039119  0.033904   \n",
      "19  0.046805  0.057342  0.030257  0.068873  0.073610  0.062976  0.054613   \n",
      "\n",
      "          7         8         9         10        11        12        13  \\\n",
      "0   0.035931  0.100506  0.044722  0.025080  0.000000  0.027620  0.011649   \n",
      "1   0.067855  0.166803  0.086246  0.067164  0.005779  0.055453  0.043319   \n",
      "2   0.035364  0.060454  0.019550  0.076931  0.000000  0.014834  0.030025   \n",
      "3   0.082660  0.083347  0.102677  0.052992  0.026106  0.011949  0.020825   \n",
      "4   0.132764  0.078576  0.076310  0.110786  0.041592  0.044076  0.056447   \n",
      "5   0.162764  0.039125  0.039573  0.050311  0.008422  0.027170  0.062899   \n",
      "6   0.081296  0.044615  0.020726  0.022992  0.010421  0.005829  0.000000   \n",
      "7   0.000000  0.057690  0.033266  0.056735  0.004864  0.028876  0.035758   \n",
      "8   0.057690  0.000000  0.107561  0.028066  0.067699  0.048026  0.044510   \n",
      "9   0.033266  0.107561  0.000000  0.062075  0.110202  0.021130  0.061828   \n",
      "10  0.056735  0.028066  0.062075  0.000000  0.091940  0.122667  0.126188   \n",
      "11  0.004864  0.067699  0.110202  0.091940  0.000000  0.045572  0.059874   \n",
      "12  0.028876  0.048026  0.021130  0.122667  0.045572  0.000000  0.058163   \n",
      "13  0.035758  0.044510  0.061828  0.126188  0.059874  0.058163  0.000000   \n",
      "14  0.093891  0.099462  0.085722  0.100223  0.029431  0.057516  0.076954   \n",
      "15  0.035825  0.062046  0.015942  0.065009  0.021502  0.036766  0.016406   \n",
      "16  0.042488  0.056924  0.016298  0.084189  0.031190  0.044171  0.044116   \n",
      "17  0.091554  0.057106  0.049359  0.086471  0.052649  0.042823  0.078300   \n",
      "18  0.059060  0.023174  0.089074  0.078308  0.018603  0.049908  0.060606   \n",
      "19  0.021254  0.054920  0.019087  0.058867  0.023415  0.033189  0.006876   \n",
      "\n",
      "          14        15        16        17        18        19  \n",
      "0   0.054892  0.044378  0.021745  0.070181  0.068122  0.046805  \n",
      "1   0.066205  0.036802  0.090299  0.080908  0.050428  0.057342  \n",
      "2   0.060191  0.039557  0.014982  0.079733  0.062793  0.030257  \n",
      "3   0.082729  0.070395  0.040984  0.139602  0.058399  0.068873  \n",
      "4   0.118508  0.056771  0.067496  0.119730  0.112498  0.073610  \n",
      "5   0.078591  0.038931  0.038400  0.087217  0.039119  0.062976  \n",
      "6   0.037649  0.012981  0.019335  0.079050  0.033904  0.054613  \n",
      "7   0.093891  0.035825  0.042488  0.091554  0.059060  0.021254  \n",
      "8   0.099462  0.062046  0.056924  0.057106  0.023174  0.054920  \n",
      "9   0.085722  0.015942  0.016298  0.049359  0.089074  0.019087  \n",
      "10  0.100223  0.065009  0.084189  0.086471  0.078308  0.058867  \n",
      "11  0.029431  0.021502  0.031190  0.052649  0.018603  0.023415  \n",
      "12  0.057516  0.036766  0.044171  0.042823  0.049908  0.033189  \n",
      "13  0.076954  0.016406  0.044116  0.078300  0.060606  0.006876  \n",
      "14  0.000000  0.080179  0.100321  0.120819  0.112492  0.040502  \n",
      "15  0.080179  0.000000  0.052674  0.039606  0.034220  0.024331  \n",
      "16  0.100321  0.052674  0.000000  0.067907  0.023408  0.058716  \n",
      "17  0.120819  0.039606  0.067907  0.000000  0.071507  0.060739  \n",
      "18  0.112492  0.034220  0.023408  0.071507  0.000000  0.047117  \n",
      "19  0.040502  0.024331  0.058716  0.060739  0.047117  0.000000  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarities = pd.DataFrame(cosine_similarity(tfidf_matrix))\n",
    "similarities[round(similarities, 0) == 1] = 0 # Suppress a document's similarity to itself\n",
    "print(\"Pairwise similarities:\")\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:55.196098Z",
     "start_time": "2017-11-10T11:14:55.124091Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two most similar segments in the corpus are\n",
      "segments 0 and 1 .\n",
      "They have a similarity score of\n",
      "0.222896735543\n"
     ]
    }
   ],
   "source": [
    "print(\"The two most similar segments in the corpus are\")\n",
    "print(\"segments\", \\\n",
    "      similarities[similarities == similarities.values.max()].idxmax(axis=0).idxmax(axis=1), \\\n",
    "      \"and\", \\\n",
    "      similarities[similarities == similarities.values.max()].idxmax(axis=0)[ similarities[similarities == similarities.values.max()].idxmax(axis=0).idxmax(axis=1) ].astype(int), \\\n",
    "      \".\")\n",
    "print(\"They have a similarity score of\")\n",
    "print(similarities.values.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alertbox alert-success\">Of course, in every set of documents, we will always find two that are similar in the sense of them being more similar to each other than to the other ones. Whether or not this actually *means* anything in terms of content is still up to scholarly interpretation. But at least it means that a scholar can look at the two documents and when she determines that they are not so similar after all, then perhaps there is something interesting to say about similar vocabulary used for different puproses. Or the other way round: When the scholar knows that two passages are similar, but they have a low \"similarity score\", shouldn't that say something about the texts's rhetorics?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering <a name=\"DocumentClustering\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering is a method to find ways of grouping data into subsets, so that these do have some cohesion. Sentences that are more similar to a particular \"paradigm\" sentence than to another one are grouped with the first one, others are grouped with their respective \"paradigm\" sentence. Of course, one of the challenges is finding sentences that work well as such paradigm sentences. So we have two (or even three) stages: Find paradigms, group data accordingly. (And learn how many groups there are.)<img src=\"http://practicalcryptography.com/media/miscellaneous/files/k_mean_send.gif\"/>\n",
    "\n",
    "I hope to be able to add a discussion of this subject soon. For now, here are nice tutorials for the process:\n",
    "  - [http://brandonrose.org/clustering](http://brandonrose.org/clustering)\n",
    "  - [https://datasciencelab.wordpress.com/2013/12/12/clustering-with-k-means-in-python/](https://datasciencelab.wordpress.com/2013/12/12/clustering-with-k-means-in-python/)\n",
    "  - [https://de.dariah.eu/tatom/working_with_text.html](https://de.dariah.eu/tatom/working_with_text.html)\n",
    "  - [http://jonathansoma.com/lede/foundations/classes/text%20processing/tf-idf/](http://jonathansoma.com/lede/foundations/classes/text%20processing/tf-idf/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Find good measure (word vectors, authorities cited, style, ...)\n",
    "  - Find starting centroids\n",
    "  - Find good K value\n",
    "  - K-Means clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with several languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us prepare a second text, this time in Spanish, and see how they compare..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:57.262304Z",
     "start_time": "2017-11-10T11:14:56.146193Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 files written.\n",
      "18 files read.\n",
      "18 labels found.\n",
      "614725 spanish wordforms known to the system.\n",
      "743 spanish stopwords known to the system.\n",
      " \n",
      "Significant words in the spanish text:\n",
      " \n",
      " Most significant words in the 1. segment:\n",
      "        lemma  tf/idf value\n",
      "0    capitvlo      0.399528\n",
      "1  totalmente      0.399528\n",
      "2     español      0.349703\n",
      "3        casa      0.286932\n",
      "4    tributar      0.286932\n",
      "5  particular      0.264527\n",
      "6      llamar      0.264527\n",
      "7        cosa      0.245585\n",
      "8    prohibir      0.245585\n",
      "9    personal      0.201756\n",
      " \n",
      " Most significant words in the 2. segment:\n",
      "        lemma  tf/idf value\n",
      "0       indio      0.176840\n",
      "1    servicio      0.158496\n",
      "2  famulicios      0.138930\n",
      "3     público      0.138930\n",
      "4  domesticos      0.138930\n",
      "5       carga      0.138930\n",
      "6    reservar      0.138930\n",
      "7       color      0.138930\n",
      "8    reperida      0.138930\n",
      "9      cobrar      0.138930\n",
      " \n",
      " Most significant words in the 3. segment:\n",
      "          lemma  tf/idf value\n",
      "0        hombre      0.382174\n",
      "1        forzar      0.334514\n",
      "2    conpadecen      0.191087\n",
      "3  emperadores3      0.191087\n",
      "4   contradecir      0.191087\n",
      "5   aristoteles      0.191087\n",
      "6      facultad      0.191087\n",
      "7   impedimetos      0.191087\n",
      "8      ocuparse      0.191087\n",
      "9        servil      0.191087\n",
      " \n",
      " Most significant words in the 4. segment:\n",
      "          lemma  tf/idf value\n",
      "0         veder      0.272392\n",
      "1      conducir      0.272392\n",
      "2      alquilar      0.272392\n",
      "3    extimables      0.272392\n",
      "4       prohibe      0.272392\n",
      "5         llano      0.272392\n",
      "6      precioso      0.272392\n",
      "7  regularmente      0.272392\n",
      "8        dignar      0.238423\n",
      "9        forzar      0.238423\n",
      " \n",
      " Most significant words in the 5. segment:\n",
      "         lemma  tf/idf value\n",
      "0       tratar      0.230925\n",
      "1       grande      0.230925\n",
      "2        razón      0.230925\n",
      "3    provincia      0.174680\n",
      "4        pagar      0.162171\n",
      "5     servicio      0.150490\n",
      "6    debiessen      0.131913\n",
      "7     discurso      0.131913\n",
      "8   permitirse      0.131913\n",
      "9  franciscano      0.131913\n",
      " \n",
      " Most significant words in the 6. segment:\n",
      "         lemma  tf/idf value\n",
      "0        indio      0.200085\n",
      "1    provisión      0.188630\n",
      "2         1549      0.188630\n",
      "3  encomendado      0.188630\n",
      "4        tasar      0.187338\n",
      "5        pagar      0.173923\n",
      "6         real      0.165106\n",
      "7    audiencia      0.165106\n",
      "8          año      0.162302\n",
      "9     voluntad      0.148416\n",
      " \n",
      " Most significant words in the 7. segment:\n",
      "        lemma  tf/idf value\n",
      "0     proveer      0.282385\n",
      "1      entrar      0.231697\n",
      "2    servicio      0.184026\n",
      "3    personal      0.162917\n",
      "4    convenir      0.161309\n",
      "5  hizieredes      0.161309\n",
      "6        vaco      0.161309\n",
      "7      holgar      0.161309\n",
      "8      juzgar      0.161309\n",
      "9       vacar      0.161309\n",
      " \n",
      " Most significant words in the 8. segment:\n",
      "       lemma  tf/idf value\n",
      "0       a el      0.235682\n",
      "1  envejecer      0.218778\n",
      "2     quitar      0.191495\n",
      "3    proveer      0.191495\n",
      "4  costumbre      0.191495\n",
      "5  audiencia      0.191495\n",
      "6     reinar      0.172137\n",
      "7     virrey      0.157121\n",
      "8      de+el      0.156100\n",
      "9    referir      0.144853\n",
      " \n",
      " Most significant words in the 9. segment:\n",
      "      lemma  tf/idf value\n",
      "0     mesmo      0.248627\n",
      "1  personal      0.212763\n",
      "2    perder      0.210663\n",
      "3   ordenar      0.210663\n",
      "4     casar      0.184391\n",
      "5     indio      0.178764\n",
      "6  voluntad      0.165751\n",
      "7  servicio      0.160220\n",
      "8    querer      0.151293\n",
      "9   tributo      0.151293\n",
      " \n",
      " Most significant words in the 10. segment:\n",
      "           lemma  tf/idf value\n",
      "0         cedula      0.281725\n",
      "1           a el      0.203724\n",
      "2     particular      0.187817\n",
      "3     presidente      0.141834\n",
      "4   encargandome      0.141834\n",
      "5        omisión      0.141834\n",
      "6          oidor      0.141834\n",
      "7       aranjuez      0.141834\n",
      "8  expressamente      0.141834\n",
      "9           limo      0.141834\n",
      " \n",
      " Most significant words in the 11. segment:\n",
      "        lemma  tf/idf value\n",
      "0      gravar      0.296242\n",
      "1       docto      0.169225\n",
      "2     materia      0.169225\n",
      "3   ajustarse      0.169225\n",
      "4      formar      0.169225\n",
      "5   diciembre      0.169225\n",
      "6        1610      0.169225\n",
      "7  reformasse      0.169225\n",
      "8       junta      0.169225\n",
      "9     haberse      0.169225\n",
      " \n",
      " Most significant words in the 12. segment:\n",
      "             lemma  tf/idf value\n",
      "0            señor      0.283368\n",
      "1          término      0.283368\n",
      "2         disponer      0.248030\n",
      "3        silvestro      0.141684\n",
      "4          ultimar      0.141684\n",
      "5          vasallo      0.141684\n",
      "6          abrazar      0.141684\n",
      "7          navarro      0.141684\n",
      "8         exacción      0.141684\n",
      "9  quebrantamiento      0.141684\n",
      " \n",
      " Most significant words in the 13. segment:\n",
      "           lemma  tf/idf value\n",
      "0         colono      0.236015\n",
      "1       celebrar      0.236015\n",
      "2         hablar      0.236015\n",
      "3      condición      0.236015\n",
      "4  adscripticios      0.236015\n",
      "5      propósito      0.236015\n",
      "6  violentamente      0.236015\n",
      "7         enseña      0.236015\n",
      "8       antiguar      0.236015\n",
      "9        volumen      0.236015\n",
      " \n",
      " Most significant words in the 14. segment:\n",
      "       lemma  tf/idf value\n",
      "0      manar      0.250435\n",
      "1   defender      0.250435\n",
      "2  excluirse      0.250435\n",
      "3     efecto      0.250435\n",
      "4    recibir      0.250435\n",
      "5  continuar      0.250435\n",
      "6   posesión      0.250435\n",
      "7   justicia      0.250435\n",
      "8    ciencia      0.250435\n",
      "9     fraude      0.250435\n",
      " \n",
      " Most significant words in the 15. segment:\n",
      "          lemma  tf/idf value\n",
      "0  prescripción      0.428202\n",
      "1        seguir      0.214101\n",
      "2         citar      0.214101\n",
      "3         lucas      0.214101\n",
      "4            fe      0.214101\n",
      "5      alegarse      0.214101\n",
      "6         valer      0.214101\n",
      "7         anuas      0.214101\n",
      "8       constar      0.214101\n",
      "9       poderse      0.214101\n",
      " \n",
      " Most significant words in the 16. segment:\n",
      "        lemma  tf/idf value\n",
      "0      gravar      0.318044\n",
      "1   inocencio      0.181679\n",
      "2    glorioso      0.181679\n",
      "3  frecuentar      0.181679\n",
      "4      africa      0.181679\n",
      "5    labrador      0.181679\n",
      "6  excessivos      0.181679\n",
      "7       mirar      0.181679\n",
      "8   estrechar      0.181679\n",
      "9    prefecto      0.181679\n",
      " \n",
      " Most significant words in the 17. segment:\n",
      "       lemma  tf/idf value\n",
      "0    señalar      0.431038\n",
      "1   tributar      0.309562\n",
      "2       cosa      0.176636\n",
      "3    contado      0.143679\n",
      "4    domingo      0.143679\n",
      "5  comodidad      0.143679\n",
      "6     demora      0.143679\n",
      "7     alegar      0.143679\n",
      "8  convencer      0.143679\n",
      "9    titular      0.143679\n",
      " \n",
      " Most significant words in the 18. segment:\n",
      "      lemma  tf/idf value\n",
      "0      apud      0.406932\n",
      "1     pagin      0.226074\n",
      "2     latir      0.180859\n",
      "3    acosta      0.177877\n",
      "4      agia      0.142301\n",
      "5     tomar      0.135644\n",
      "6       ego      0.135644\n",
      "7      dict      0.135644\n",
      "8    librar      0.097416\n",
      "9  capítulo      0.097416\n"
     ]
    }
   ],
   "source": [
    "bigspanishfile = 'Solorzano/Sections_II.2_PI.txt'\n",
    "spInput = open(bigspanishfile, encoding='utf-8').readlines()\n",
    "\n",
    "spAt    = -1\n",
    "spDest  = None\n",
    "\n",
    "for line in spInput:\n",
    "    if line[0:3] == '€€€':\n",
    "        if spDest:\n",
    "            spDest.close()\n",
    "        spAt += 1\n",
    "        spDest = open(outputBase + '.' + str(spAt) +\n",
    "                    '.spanish.txt', encoding='utf-8', mode='w')\n",
    "    else:\n",
    "        spDest.write(line.strip())\n",
    "\n",
    "spAt += 1\n",
    "spDest.close()\n",
    "print(str(spAt) + ' files written.')\n",
    "\n",
    "spSuffix = '.spanish.txt'\n",
    "spCorpus = []\n",
    "for i in range(0, spAt):\n",
    "    try:\n",
    "        with open(path + '/' + filename + str(i) + spSuffix, encoding='utf-8') as f:\n",
    "            spCorpus.append(f.read())\n",
    "            f.close()\n",
    "    except IOError as exc:\n",
    "        if exc.errno != errno.EISDIR:  # Do not fail if a directory is found, just ignore it.\n",
    "            raise                      # Propagate other kinds of IOError.\n",
    "\n",
    "print(str(len(spCorpus)) + ' files read.')\n",
    "\n",
    "# Labels\n",
    "spLabel = []\n",
    "i = 0\n",
    "for spLine in spInput:\n",
    "    if spLine[0:3] == '€€€':\n",
    "        spLabel.append(spLine[6:].strip())\n",
    "        i =+ 1\n",
    "print(str(len(spLabel)) + ' labels found.')\n",
    "\n",
    "# Tokens\n",
    "spTokenised = []\n",
    "for spSegment in spCorpus:\n",
    "    spTokenised.append(list(filter(None, (spWord.lower()\n",
    "                                        for spWord in re.split('\\W+', spSegment)))))\n",
    "\n",
    "# Lemmata\n",
    "spLemma    = {}\n",
    "spTempdict = []\n",
    "spWordfile_path = 'Solorzano/wordforms-es.txt'\n",
    "spWordfile = open(spWordfile_path, encoding='utf-8')\n",
    "\n",
    "for spLine in spWordfile.readlines():\n",
    "    spTempdict.append(tuple(spLine.split('>')))\n",
    "\n",
    "spLemma = {k.strip(): v.strip() for k, v in spTempdict}\n",
    "spWordfile.close\n",
    "print(str(len(spLemma)) + ' spanish wordforms known to the system.')\n",
    "\n",
    "# Stopwords\n",
    "spStopwords_path = 'Solorzano/stopwords-es.txt'\n",
    "spStopwords = open(spStopwords_path, encoding='utf-8').read().splitlines()\n",
    "print(str(len(spStopwords)) + ' spanish stopwords known to the system.')\n",
    "\n",
    "print(' ')\n",
    "print('Significant words in the spanish text:')\n",
    "\n",
    "# tokenising and lemmatising function\n",
    "def spOurLemmatiser(str_input):\n",
    "    spWordforms = re.split('\\W+', str_input)\n",
    "    return [spLemma[spWordform].lower() if spWordform in spLemma else spWordform.lower() for spWordform in spWordforms ]\n",
    "\n",
    "spTfidf_vectorizer = TfidfVectorizer(stop_words=spStopwords, use_idf=True, tokenizer=spOurLemmatiser, norm='l2')\n",
    "spTfidf_matrix = spTfidf_vectorizer.fit_transform(spCorpus)\n",
    "\n",
    "spMx_array = spTfidf_matrix.toarray()\n",
    "spFn = spTfidf_vectorizer.get_feature_names()\n",
    "\n",
    "pos = 1\n",
    "for l in spMx_array:\n",
    "    print(' ')\n",
    "    print(' Most significant words in the ' + str(pos) + '. segment:')\n",
    "    print(pd.DataFrame.rename(pd.DataFrame.from_dict([(spFn[x], l[x]) for x in (l*-1).argsort()][:10]), columns={0:'lemma',1:'tf/idf value'}))\n",
    "    pos += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alertbox alert-success\">Our spanish wordfiles ([lemmata list](Solorzano/wordforms-es.txt) and [stopwords list](Solorzano/stopwords-es.txt)) are quite large and generous - they spare us some work of resolving quite a lot of abbreviations. However, since they are actually originating from a completely different project, it is very unlikely, that this goes without mistakes. Also some lemmata (like \"de+el\" in the eighth segment) are not really such. So we need to clean our wordlist and adapt it to the current text material urgently!</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now imagine how we would bring the two documents together in a vector space. We would generate dimensions for all the words of our spanish vocabulary and would end up with a common space of roughly twice as many dimensions as before - and the latin work would be only in the first half of the dimensions and the spanish work only in the second half. The respective other half would be populated with only zeroes. So in effect, we would not really have a *common* space or something on the basis of which we could compare the two works. :-("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What might be an interesting perspective, however - since in this case, the second text is a translation of the first one - is a parallel, synoptic overview of both texts. So, let's at least add the second text to our html overview with the wordclouds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:14:59.064485Z",
     "start_time": "2017-11-10T11:14:57.457324Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "htmlfile2 = open(outputDir + '/Synopsis.html', encoding='utf-8', mode='w')\n",
    "\n",
    "htmlfile2.write(\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "    <head>\n",
    "        <title>Section Characteristics, parallel view</title>\n",
    "        <meta charset=\"utf-8\"/>\n",
    "    </head>\n",
    "    <body>\n",
    "        <table>\n",
    "\"\"\")\n",
    "spA = [[]]\n",
    "spA.clear()\n",
    "spDicts = []\n",
    "spW = []\n",
    "for i in range(0, max(len(mx_array), len(spMx_array))):\n",
    "    if (i > len(mx_array) - 1):\n",
    "        htmlfile2.write(\"\"\"\n",
    "            <tr>\n",
    "                <td>\n",
    "                    <head>Section {a}: n/a</head>\n",
    "                </td>\"\"\".format(a = str(i)))\n",
    "    else:\n",
    "        htmlfile2.write(\"\"\"\n",
    "            <tr>\n",
    "                <td>\n",
    "                    <head>Section {a}: <b>{b}</b></head><br/>\n",
    "                    <img src=\"./wc_{a}.png\"/><br/>\n",
    "                    <small><i>length: {c} words</i></small>\n",
    "                </td>\"\"\".format(a = str(i), b = label[i], c = len(tokenised[i])))\n",
    "    if (i > len(spMx_array) - 1):\n",
    "        htmlfile2.write(\"\"\"\n",
    "                <td>\n",
    "                    <head>Section {a}: n/a</head>\n",
    "                </td>\n",
    "            </tr><tr><td>&nbsp;</td></tr>\"\"\".format(a = str(i)))\n",
    "    else:\n",
    "        spA.append([ int(round(x * 100000, 0)) for x in spMx_array[i]])\n",
    "        spDicts.append(dict(zip(spFn, spA[i])))\n",
    "        spW.append(WordCloud(background_color=None, mode=\"RGBA\", \\\n",
    "                           max_font_size=40, min_font_size=10, \\\n",
    "                           max_words=60, relative_scaling=0.8).fit_words(spDicts[i]))\n",
    "        spW[i].to_file(outputDir + '/wc_' + str(i) + '_sp.png')\n",
    "        htmlfile2.write(\"\"\"\n",
    "                <td>\n",
    "                    <head>Section {d}: <b>{e}</b></head><br/>\n",
    "                    <img src=\"./wc_{d}_sp.png\"/><br/>\n",
    "                    <small><i>length: {f} words</i></small>\n",
    "                </td>\n",
    "            </tr>\n",
    "            <tr><td>&nbsp;</td></tr>\"\"\".format(d = str(i), e = spLabel[i], f = len(spTokenised[i])))\n",
    "    \n",
    "htmlfile2.write(\"\"\"\n",
    "        </table>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\")\n",
    "htmlfile2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the resulting file can be opened [here](Solorzano/Synopsis.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-30T12:30:15.482766Z",
     "start_time": "2017-08-30T14:30:15.474338+02:00"
    }
   },
   "source": [
    "## Translations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe there is an approach to inter-lingual comparison after all. Here is the [API documentation](https://github.com/commonsense/conceptnet5/wiki/API) of [conceptnet.io](http://conceptnet.io), which we can use to lookup synonyms, related terms and translations. Like with such a URI:\n",
    "\n",
    "[http://api.conceptnet.io/related/c/la/rex?filter=/c/es](http://api.conceptnet.io/related/c/la/rex?filter=/c/es)\n",
    "\n",
    "We can get an identifier for a word and many possible translations for this word. So, we could - this remains to be tested in practice - look up our ten (or so) most frequent words in one language and collect all possible translations in the second language. Then we could compare these with what we actually find in the second work. How much overlap there is going to be and how univocal it is going to be remains to be seen, however..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, with a single segment, we could do something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T11:33:14.195313Z",
     "start_time": "2017-11-10T11:33:11.728113Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing words from segments 6 (latin) and 8 (spanish)...\n",
      " \n",
      "Most significant words in the latin text:\n",
      "['semi', 'haya', 'por', 'casso', 'pario', 'volo', 'paro', 'servicios', 'servicio', 'personal', 'indios', 'tribuo']\n",
      " \n",
      " \n",
      "For each of the latin words, here are possible translations:\n",
      "semi:\n",
      "mitad, semi, medio, parcialmente, media, parte, mediano, cora, intermedio, parcial, tercio, semifinal, mediana, cuasi, cuarta\n",
      "haya:\n",
      "haya, hamás, ele, jeque, alteza, cordobés, mahoma, córdoba, tanzania, princesa, árabe, israel, tablón, malentendido, palestina\n",
      "por:\n",
      "veces, ésos, ele, aquéllos, aquéllas, ésas, éste, doña, aquél, por, hai, éstas, ia, ése, favor\n",
      "casso:\n",
      "caer, caída, recaer, caerse, caído, comenzar, empezar, empiece, empiezo, comienzo, empezado, inicio, iniciar, iniciarse, vacilar\n",
      "volo:\n",
      "vuelo, volando, volar, avión, copiloto, chicago, paloma, palomar, milán, volador, mosca, pájaro, piloto, aves, aviación\n",
      "paro:\n",
      "huelga, paro, nepal, desempleo, perú, pelotudo, desempleado, paraguay, laburo, desocupación, delhi, lama, boludo, uruguay, bolivia\n",
      "personal:\n",
      "individual, personalmente, particular, personal, personales, individuo, privado, individualidad, personalidad, propio, espiritual, su, personalizado, subjetivo, suyo\n",
      " \n",
      " \n",
      "Most significant words in the spanish text:\n",
      "['mesmo', 'personal', 'perder', 'ordenar', 'casar', 'indio', 'voluntad', 'servicio', 'querer', 'tributo', 'encomendar', 'cosa']\n",
      " \n",
      " \n",
      "Overlaps:\n",
      "semi\n",
      "haya\n",
      "por\n",
      "\n",
      "\n",
      "paro\n",
      "personal\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "segment_no = 6\n",
    "spSegment_no = 8\n",
    "\n",
    "print(\"Comparing words from segments \" + str(segment_no) + \" (latin) and \" + str(spSegment_no) + \" (spanish)...\")\n",
    "\n",
    "print(\" \")\n",
    "# Build List of most significant words for a segment\n",
    "top10a = []\n",
    "top10a = ([fn[x] for x in (mx_array[segment_no]*-1).argsort()][:12])\n",
    "print(\"Most significant words in the latin text:\")\n",
    "print(top10a)\n",
    "\n",
    "print(\" \")\n",
    "# Build lists of possible translations (the 15 most closely related ones)\n",
    "top10a_possible_translations = defaultdict(list)\n",
    "for word in top10a:\n",
    "    concepts_uri = \"http://api.conceptnet.io/related/c/la/\" + word + \"?filter=/c/es\"\n",
    "    response = urllib.request.urlopen(concepts_uri)\n",
    "    concepts = json.loads(response.read().decode(response.info().get_param('charset') or 'utf-8'))\n",
    "    for rel in concepts[\"related\"][0:15]:\n",
    "        top10a_possible_translations[word].append(rel.get(\"@id\").split('/')[-1])\n",
    "\n",
    "print(\" \")\n",
    "print(\"For each of the latin words, here are possible translations:\")\n",
    "for word in top10a_possible_translations:\n",
    "    print(word + \":\")\n",
    "    print(', '.join(trans for trans in top10a_possible_translations[word]))\n",
    "\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "# Build list of 10 most significant words in the second language\n",
    "top10b = []\n",
    "top10b = ([spFn[x] for x in (spMx_array[spSegment_no]*-1).argsort()][:12])\n",
    "print(\"Most significant words in the spanish text:\")\n",
    "print(top10b)\n",
    "\n",
    "# calculate number of overlapping terms\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\"Overlaps:\")\n",
    "for word in top10a_possible_translations:\n",
    "    print(', '.join(trans for trans in top10a_possible_translations[word] if (trans in top10b or trans == word)))\n",
    "\n",
    "# do a nifty ranking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph-based NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - [Unsupervised keywords extraction using graphs](https://graphaware.com/neo4j/2017/10/03/efficient-unsupervised-topic-extraction-nlp-neo4j.html)\n",
    "  - [Reverse Engineering Book Stories with Neo4j and GraphAware NLP](https://graphaware.com/neo4j/2017/07/24/reverse-engineering-book-stories-nlp.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - http://jonathansoma.com/lede/foundations/classes/text%20processing/tf-idf/\n",
    "  - http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/\n",
    "  - http://blog.christianperone.com/2011/10/machine-learning-text-feature-extraction-tf-idf-part-ii/\n",
    "  - https://de.dariah.eu/tatom/index.html\n",
    "  - https://stanford.edu/~rjweiss/public_html/IRiSS2013/text2/notebooks/tfidf.html\n",
    "  - http://takwatanabe.me/data_science/pyspark/cs110_lab3b.html\n",
    "  - https://github.com/mccurdyc/tf-idf/blob/master/README.md\n",
    "  - https://people.duke.edu/~ccc14/sta-663/TextProcessingExtras.html\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "245px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
